{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6376419e",
      "metadata": {
        "id": "6376419e"
      },
      "source": [
        "# å®éªŒä»»åŠ¡äºŒ: RNNã€LSTMå’ŒGRUæ–‡æœ¬ç”Ÿæˆä»»åŠ¡\n",
        "\n",
        "## **1. æ–‡æœ¬é¢„å¤„ç†**\n",
        "æ–‡æœ¬é¢„å¤„ç†ç®€ä»‹\n",
        "    æ–‡æœ¬é¢„å¤„ç†æ˜¯åœ¨æ·±åº¦å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä»»åŠ¡ä¸­ï¼Œå¯¹åŸå§‹æ–‡æœ¬è¿›è¡Œæ¸…ç†ã€è½¬æ¢å’Œæ ¼å¼åŒ–ï¼Œä½¿å…¶èƒ½å¤Ÿè¢«æ¨¡å‹ç†è§£å’Œå¤„ç†çš„è¿‡ç¨‹ã€‚\n",
        "\n",
        "é¢„å¤„ç†çš„å¿…è¦æ€§\n",
        "    åŸå§‹æ–‡æœ¬å¯èƒ½åŒ…å«å™ªå£°ï¼Œä¸”æ–‡æœ¬é•¿åº¦ä¸ä¸€è‡´ï¼Œå¯¼è‡´æ‰¹é‡è®­ç»ƒæ—¶éœ€è¦å¡«å……\n",
        "\n",
        "AG News æ•°æ®é›†ç®€ä»‹\n",
        "\n",
        "    AG News æ•°æ®é›†æ¥æºäº AG's corpus of news articlesï¼Œæ˜¯ä¸€ä¸ªå¤§å‹çš„æ–°é—»æ•°æ®é›†ï¼Œç”± Antonio Gulli ä»å¤šä¸ªæ–°é—»ç½‘ç«™æ”¶é›†æ•´ç†ã€‚\n",
        "    AG News æ•°æ®é›†åŒ…å« 4 ç±»æ–°é—»ï¼Œæ¯ç±» 30,000 æ¡è®­ç»ƒæ•°æ®ï¼Œå…± 120,000 æ¡è®­ç»ƒæ ·æœ¬ å’Œ 7,600 æ¡æµ‹è¯•æ ·æœ¬ã€‚\n",
        "\n",
        "é¦–å…ˆå¯¼å…¥æ‰€éœ€æ¨¡å—ï¼š\n",
        "\n",
        "å¯èƒ½éœ€è¦å®‰è£…datasetsåŒ…\n"
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f870a68277a4854a",
        "outputId": "e3ed94b3-82f3-4705-d501-ff721c979689"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.4.1-py3-none-any.whl (487 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.4.1 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "execution_count": 3,
      "source": [
        "pip install datasets"
      ],
      "id": "f870a68277a4854a"
    },
    {
      "metadata": {
        "id": "17399ab3db54117"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 4,
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from datasets import load_dataset, load_from_disk\n",
        "from collections import Counter\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import os"
      ],
      "id": "17399ab3db54117"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jwbecz-aVN3m",
        "outputId": "a80f3445-b785-4115-9407-ddc11e412a26"
      },
      "id": "Jwbecz-aVN3m",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "7c858707e89b9c13"
      },
      "cell_type": "markdown",
      "source": [
        "æˆ‘ä»¬ä»AG News æ•°æ®é›†ä¸­åŠ è½½æ–‡æœ¬ã€‚ è¿™æ˜¯ä¸€ä¸ªè¾ƒå°çš„è¯­æ–™åº“ï¼Œæœ‰150000å¤šä¸ªå•è¯ï¼Œä½†è¶³å¤Ÿæˆ‘ä»¬å°è¯•ç‰›åˆ€.\n"
      ],
      "id": "7c858707e89b9c13"
    },
    {
      "metadata": {
        "id": "caf5d0a68732b84d"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 6,
      "source": [
        "data_path = \"./drive/MyDrive/ag_news\"\n",
        "dataset = load_from_disk(data_path)\n",
        "\n",
        "# æå–æ‰€æœ‰æ–‡æœ¬æ•°æ®\n",
        "train_text = [item['text'] for item in dataset['train']]\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "id": "caf5d0a68732b84d"
    },
    {
      "metadata": {
        "id": "78ab1a668ad3d165"
      },
      "cell_type": "markdown",
      "source": [
        "è¯å…ƒåŒ–\n",
        "ä¸‹é¢çš„tokenizeå‡½æ•°å°†æ–‡æœ¬è¡Œåˆ—è¡¨ï¼ˆlinesï¼‰ä½œä¸ºè¾“å…¥ï¼Œ åˆ—è¡¨ä¸­çš„æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªæ–‡æœ¬åºåˆ—ï¼ˆå¦‚ä¸€æ¡æ–‡æœ¬è¡Œï¼‰ã€‚ æ¯ä¸ªæ–‡æœ¬åºåˆ—åˆè¢«æ‹†åˆ†æˆä¸€ä¸ªè¯å…ƒåˆ—è¡¨ï¼Œè¯å…ƒï¼ˆtokenï¼‰æ˜¯æ–‡æœ¬çš„åŸºæœ¬å•ä½ã€‚ æœ€åï¼Œè¿”å›ä¸€ä¸ªç”±è¯å…ƒåˆ—è¡¨ç»„æˆçš„åˆ—è¡¨ï¼Œå…¶ä¸­çš„æ¯ä¸ªè¯å…ƒéƒ½æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ˆstringï¼‰ã€‚\n"
      ],
      "id": "78ab1a668ad3d165"
    },
    {
      "metadata": {
        "id": "2748b26c2e6c70f6"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 7,
      "source": [
        "# ä½¿ç”¨ split è¿›è¡Œåˆ†è¯\n",
        "def tokenize(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "# ç”Ÿæˆè¯æ±‡è¡¨\n",
        "counter = Counter()\n",
        "for text in train_text:\n",
        "    counter.update(tokenize(text))"
      ],
      "id": "2748b26c2e6c70f6"
    },
    {
      "metadata": {
        "id": "b1f7962eff64eb92"
      },
      "cell_type": "markdown",
      "source": [
        "è¯å…ƒçš„ç±»å‹æ˜¯å­—ç¬¦ä¸²ï¼Œè€Œæ¨¡å‹éœ€è¦çš„è¾“å…¥æ˜¯æ•°å­—ï¼Œå› æ­¤è¿™ç§ç±»å‹ä¸æ–¹ä¾¿æ¨¡å‹ä½¿ç”¨ã€‚ ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ„å»ºä¸€ä¸ªå­—å…¸ï¼Œé€šå¸¸ä¹Ÿå«åšè¯è¡¨ï¼ˆvocabularyï¼‰ï¼Œ ç”¨æ¥å°†å­—ç¬¦ä¸²ç±»å‹çš„è¯å…ƒæ˜ å°„åˆ°ä»0å¼€å§‹çš„æ•°å­—ç´¢å¼•ä¸­ã€‚\n",
        "é¦–å…ˆï¼Œå®šä¹‰ç‰¹æ®Šæ ‡è®°ï¼ˆå¦‚ <unk> ä»£è¡¨æœªçŸ¥è¯ï¼Œ<pad> ç”¨äºåºåˆ—å¡«å……ï¼Œ<bos>è¡¨ç¤ºåºåˆ—å¼€å§‹ï¼Œ<eos>è¡¨ç¤ºåºåˆ—ç»“æŸï¼‰ã€‚ç„¶åï¼Œä» Counter ç»Ÿè®¡çš„å•è¯é¢‘ç‡åˆ—è¡¨ä¸­æå–æ‰€æœ‰å•è¯ï¼Œå¹¶æŒ‰é¢‘ç‡æ’åºï¼Œå°†å…¶æ·»åŠ åˆ°è¯æ±‡è¡¨ä¸­ã€‚æœ€åï¼Œä½¿ç”¨ enumerate ä¸ºæ¯ä¸ªå•è¯åˆ†é…å”¯ä¸€ç´¢å¼•ï¼Œåˆ›å»ºä¸€ä¸ª word-to-index æ˜ å°„ï¼Œæ–¹ä¾¿å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å€¼åºåˆ—ä¾›æ·±åº¦å­¦ä¹ æ¨¡å‹ä½¿ç”¨ã€‚\n"
      ],
      "id": "b1f7962eff64eb92"
    },
    {
      "metadata": {
        "id": "e4beb7d758643a55"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 8,
      "source": [
        "# ç”Ÿæˆè¯æ±‡è¡¨ï¼ŒåŒ…å«ç‰¹æ®Š token\n",
        "special_tokens = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
        "vocab = special_tokens + [word for word, _ in counter.most_common()]\n",
        "vocab_dict = {word: idx for idx, word in enumerate(vocab)}"
      ],
      "id": "e4beb7d758643a55"
    },
    {
      "metadata": {
        "id": "a53a0504ff359aa7"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "æ‰“å°è¯æ±‡è¡¨å¤§å°ï¼Œå‰10ä¸ªé«˜é¢‘è¯å…ƒåŠå…¶ç´¢å¼•ã€‚"
      ],
      "id": "a53a0504ff359aa7"
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "161c78fff5d25175",
        "outputId": "766ba53e-8693-4b1e-d788-d9f1c5812b6e"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "è¯æ±‡è¡¨å¤§å°: 158737\n",
            "å‰ 10 ä¸ªæœ€å¸¸è§çš„å•è¯åŠå…¶ç´¢å¼•:\n",
            "å•è¯: the, ç´¢å¼•: 4\n",
            "å•è¯: to, ç´¢å¼•: 5\n",
            "å•è¯: a, ç´¢å¼•: 6\n",
            "å•è¯: of, ç´¢å¼•: 7\n",
            "å•è¯: in, ç´¢å¼•: 8\n",
            "å•è¯: and, ç´¢å¼•: 9\n",
            "å•è¯: on, ç´¢å¼•: 10\n",
            "å•è¯: for, ç´¢å¼•: 11\n",
            "å•è¯: -, ç´¢å¼•: 12\n",
            "å•è¯: #39;s, ç´¢å¼•: 13\n"
          ]
        }
      ],
      "execution_count": 9,
      "source": [
        "print(\"è¯æ±‡è¡¨å¤§å°:\", len(vocab_dict))\n",
        "print(\"å‰ 10 ä¸ªæœ€å¸¸è§çš„å•è¯åŠå…¶ç´¢å¼•:\")\n",
        "#TODO:æ‰“å°å‰10ä¸ªé«˜é¢‘è¯å…ƒåŠå…¶ç´¢å¼•\n",
        "top_10_tokens = counter.most_common(10)\n",
        "for token in top_10_tokens:\n",
        "    word, freq = token\n",
        "    print(f\"å•è¯: {word}, ç´¢å¼•: {vocab_dict[word]}\")"
      ],
      "id": "161c78fff5d25175"
    },
    {
      "metadata": {
        "id": "b734720ce2043c4"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "    æ€è€ƒé¢˜1ï¼šåœ¨æ–‡æœ¬å¤„ç†ä¸­ï¼Œä¸ºä»€ä¹ˆéœ€è¦å¯¹æ–‡æœ¬è¿›è¡Œåˆ†è¯ï¼ˆTokenizationï¼‰ï¼Ÿ\n",
        "\n",
        "    æ€è€ƒé¢˜2ï¼šåœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œä¸ºä»€ä¹ˆä¸èƒ½ç›´æ¥ä½¿ç”¨å•è¯è€Œéœ€è¦å°†å…¶è½¬æ¢ä¸ºç´¢å¼•ï¼Ÿ"
      ],
      "id": "b734720ce2043c4"
    },
    {
      "metadata": {
        "id": "f4fc14a970d1d30f"
      },
      "cell_type": "markdown",
      "source": [
        "## **2. RNNæ–‡æœ¬ç”Ÿæˆå®éªŒ**\n",
        "\n",
        "\"RNNæ–‡æœ¬ç”Ÿæˆæ¦‚è¿°\"\n",
        "\n",
        "    ä½¿ç”¨RNNè¿›è¡Œæ–‡æœ¬ç”Ÿæˆä»»åŠ¡çš„æ ¸å¿ƒæ€æƒ³æ˜¯ æ ¹æ®å‰é¢çš„æ–‡æœ¬é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼Œç„¶åå°†é¢„æµ‹å‡ºçš„å•è¯ä½œä¸ºè¾“å…¥ï¼Œå¾ªç¯è¿­ä»£ç”Ÿæˆå®Œæ•´æ–‡æœ¬ã€‚æœ¬å®éªŒä»¥AG News æ•°æ®ä¸ºä¾‹ï¼Œç»™å®šå‰100ä¸ªå•è¯ä½œä¸ºè¾“å…¥ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼Œå®ç°æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ã€‚\n",
        "\n",
        "\"RNNçš„å±€é™æ€§\"\n",
        "\n",
        "    RNNçš„å±€é™æ€§åœ¨äºéš¾ä»¥è®°ä½é•¿è·ç¦»ä¸Šä¸‹æ–‡ï¼Œå®¹æ˜“å¯¼è‡´ç”Ÿæˆå†…å®¹ç¼ºä¹è¿è´¯æ€§ï¼Œä¸”å¯èƒ½å‡ºç°é‡å¤æˆ–æ¨¡å¼åŒ–çš„æ–‡æœ¬ã€‚\n",
        "\n",
        "![ç¤ºä¾‹å›¾ç‰‡](pics/rnn.png)\n",
        "\n",
        "### å‰ç½®ä»£ç \n",
        "\n",
        "é¦–å…ˆå¯¼å…¥æ‰€éœ€æ¨¡å—ï¼š"
      ],
      "id": "f4fc14a970d1d30f"
    },
    {
      "metadata": {
        "id": "910d8e3c07f67072"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 10,
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from datasets import load_dataset, load_from_disk\n",
        "from collections import Counter\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import os"
      ],
      "id": "910d8e3c07f67072"
    },
    {
      "metadata": {
        "id": "9e5dfbf26750f226"
      },
      "cell_type": "markdown",
      "source": [
        "è¯»å–æ•°æ®é›†"
      ],
      "id": "9e5dfbf26750f226"
    },
    {
      "metadata": {
        "id": "8717c9e95d9e8e58"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 11,
      "source": [
        "data_path = \"./drive/MyDrive/ag_news\"\n",
        "dataset = load_from_disk(data_path)\n",
        "\n",
        "# æå–æ‰€æœ‰æ–‡æœ¬æ•°æ®\n",
        "train_text = [item['text'] for item in dataset['train']]\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "id": "8717c9e95d9e8e58"
    },
    {
      "metadata": {
        "id": "80d041e69fb63a3"
      },
      "cell_type": "markdown",
      "source": [
        "æ–‡æœ¬çš„é¢„å¤„ç†"
      ],
      "id": "80d041e69fb63a3"
    },
    {
      "metadata": {
        "id": "ea3afddf94ced251"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 12,
      "source": [
        "\n",
        "# ä½¿ç”¨ split è¿›è¡Œåˆ†è¯\n",
        "def tokenize(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "# ç”Ÿæˆè¯æ±‡è¡¨\n",
        "counter = Counter()\n",
        "for text in train_text:\n",
        "    counter.update(tokenize(text))\n",
        "\n",
        "# ç”Ÿæˆè¯æ±‡è¡¨ï¼ŒåŒ…å«ç‰¹æ®Š token\n",
        "special_tokens = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
        "vocab = special_tokens + [word for word, _ in counter.most_common()]\n",
        "vocab_dict = {word: idx for idx, word in enumerate(vocab)}\n"
      ],
      "id": "ea3afddf94ced251"
    },
    {
      "metadata": {
        "id": "cf8d9b04dd0c2f9e"
      },
      "cell_type": "markdown",
      "source": [
        "### è®­ç»ƒæ•°æ®ç”Ÿæˆ\n",
        "\n",
        "å°†æ–‡æœ¬æ•°æ®è½¬æ¢ä¸ºæ•°å€¼è¡¨ç¤ºï¼Œå¹¶æŒ‰100ä¸ªå•è¯ä½œä¸ºè¾“å…¥ã€ä¸‹ä¸€ä¸ªå•è¯ä½œä¸ºç›®æ ‡çš„æ–¹å¼æ„é€ è®­ç»ƒæ•°æ®ã€‚æœ€ç»ˆç”Ÿæˆ X_trainï¼ˆè¾“å…¥åºåˆ—ï¼‰å’Œ Y_trainï¼ˆé¢„æµ‹ç›®æ ‡ï¼‰ï¼Œç”¨äº RNN è®­ç»ƒæ–‡æœ¬ç”Ÿæˆæ¨¡å‹ã€‚\n"
      ],
      "id": "cf8d9b04dd0c2f9e"
    },
    {
      "metadata": {
        "id": "d33c3dfdd9212f39"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 13,
      "source": [
        "\n",
        "def numericalize(text):\n",
        "    return torch.tensor([vocab_dict.get(word, vocab_dict[\"<unk>\"]) for word in tokenize(text)], dtype=torch.long)\n",
        "\n",
        "# ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼ˆè¾“å…¥ 100 ä¸ªè¯ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼‰\n",
        "def create_data(text_list, seq_len=100):\n",
        "    X, Y = [], []\n",
        "    for text in text_list:\n",
        "        token_ids = numericalize(text)\n",
        "        if len(token_ids) <= seq_len:\n",
        "            continue  # å¿½ç•¥è¿‡çŸ­çš„æ–‡æœ¬\n",
        "        for i in range(len(token_ids) - seq_len):\n",
        "            X.append(token_ids[i:i + seq_len])\n",
        "            Y.append(token_ids[i + seq_len])\n",
        "    return torch.stack(X), torch.tensor(Y)\n",
        "\n",
        "# ç”Ÿæˆè®­ç»ƒæ•°æ®\n",
        "X_train, Y_train = create_data(train_text, seq_len=100)\n",
        "\n",
        "\n",
        "# åˆ›å»º DataLoader\n",
        "batch_size = 32\n",
        "train_data = torch.utils.data.TensorDataset(X_train, Y_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n"
      ],
      "id": "d33c3dfdd9212f39"
    },
    {
      "metadata": {
        "id": "f47ecbe3b4987b16"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "    æ€è€ƒé¢˜3ï¼šå¦‚æœä¸æ‰“ä¹±è®­ç»ƒé›†ï¼Œä¼šå¯¹ç”Ÿæˆä»»åŠ¡æœ‰ä»€ä¹ˆå½±å“ï¼Ÿ\n",
        "\n",
        "\n",
        "### RNN æ¨¡å‹æ„å»º\n",
        "\n",
        "å®ç°äº†ä¸€ä¸ªåŸºäº RNN çš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡è¾“å…¥æ–‡æœ¬åºåˆ—é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ã€‚"
      ],
      "id": "f47ecbe3b4987b16"
    },
    {
      "metadata": {
        "id": "147d6c280095cc9a"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 14,
      "source": [
        "class RNNTextGenerator(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=2):\n",
        "        super(RNNTextGenerator, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)#å°†è¾“å…¥çš„å•è¯ç´¢å¼•è½¬æ¢ä¸º embed_dim ç»´çš„å‘é‡ã€‚\n",
        "        self.rnn = nn.RNN(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True)#æ„å»ºä¸€ä¸ª RNN å±‚ï¼Œç”¨äºå¤„ç†åºåˆ—æ•°æ®ã€‚\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)#å°† RNN éšè—çŠ¶æ€ æ˜ å°„åˆ° è¯æ±‡è¡¨å¤§å°çš„å‘é‡ï¼Œç”¨äºé¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯çš„æ¦‚ç‡åˆ†å¸ƒã€‚\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        #è¾“å…¥ x å½¢çŠ¶ï¼š(batch_size, seq_len)\n",
        "        #è¾“å‡º embedded å½¢çŠ¶ï¼š(batch_size, seq_len, embed_dim)\n",
        "        embedded = self.embedding(x)\n",
        "        #è¾“å…¥ embedded å½¢çŠ¶ï¼š(batch_size, seq_len, embed_dim)\n",
        "        #è¾“å‡º output å½¢çŠ¶ï¼š(batch_size, seq_len, hidden_dim)ï¼ˆæ‰€æœ‰æ—¶é—´æ­¥çš„éšè—çŠ¶æ€ï¼‰\n",
        "        #è¾“å‡º hidden å½¢çŠ¶ï¼š(num_layers, batch_size, hidden_dim)ï¼ˆæœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ï¼‰\n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "        #åªå– æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ output[:, -1, :] ä½œä¸ºè¾“å…¥\n",
        "        #é€šè¿‡å…¨è¿æ¥å±‚ self.fc å°†éšè—çŠ¶æ€è½¬æ¢ä¸ºè¯æ±‡è¡¨å¤§å°çš„åˆ†å¸ƒï¼ˆç”¨äºé¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼‰\n",
        "        #æœ€ç»ˆ output å½¢çŠ¶ï¼š(batch_size, vocab_size)\n",
        "        output = self.fc(output[:, -1, :])\n",
        "        return output, hidden"
      ],
      "id": "147d6c280095cc9a"
    },
    {
      "metadata": {
        "id": "d5f0eae4db36a71"
      },
      "cell_type": "markdown",
      "source": [
        "å®šä¹‰æ¨¡å‹æ‰€éœ€å‚æ•°ã€å®ä¾‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨"
      ],
      "id": "d5f0eae4db36a71"
    },
    {
      "metadata": {
        "id": "c7b124a501affec7"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 15,
      "source": [
        "embed_dim = 128\n",
        "hidden_dim = 512\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "model = RNNTextGenerator(vocab_size, embed_dim, hidden_dim, num_layers=2).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "id": "c7b124a501affec7"
    },
    {
      "metadata": {
        "id": "83f9e86d4297477c"
      },
      "cell_type": "markdown",
      "source": [
        "### RNN æ¨¡å‹è®­ç»ƒ\n",
        "\n",
        "RNN è®­ç»ƒè¿‡ç¨‹"
      ],
      "id": "83f9e86d4297477c"
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e3a4b5e87d77a12",
        "outputId": "a7fa18a2-8f9a-4714-e49f-aca9c137430f"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:06<00:00, 18.27it/s, loss=9.19]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Avg Loss: 10.0265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 21.02it/s, loss=7.79]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Avg Loss: 9.3537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.59it/s, loss=11.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Avg Loss: 9.0994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 21.03it/s, loss=9.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Avg Loss: 9.0353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.71it/s, loss=7.98]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Avg Loss: 8.9858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 21.04it/s, loss=9.33]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Avg Loss: 8.9659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.81it/s, loss=10.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Avg Loss: 8.9667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.79it/s, loss=9.26]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Avg Loss: 8.9386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.95it/s, loss=8.84]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Avg Loss: 8.9334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.40it/s, loss=9.93]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Avg Loss: 8.9320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.87it/s, loss=9.23]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Avg Loss: 8.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.52it/s, loss=9.25]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Avg Loss: 8.8629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.87it/s, loss=9.14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Avg Loss: 8.8111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.80it/s, loss=8.68]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Avg Loss: 8.2409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.66it/s, loss=6.83]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Avg Loss: 7.4543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.82it/s, loss=10.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Avg Loss: 9.0887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.53it/s, loss=9.42]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Avg Loss: 8.8777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.86it/s, loss=8.95]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18, Avg Loss: 8.7297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.73it/s, loss=8.89]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19, Avg Loss: 8.5546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.68it/s, loss=7.94]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Avg Loss: 8.3486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 16,
      "source": [
        "def train_model(model, train_loader, epochs=5):\n",
        "    model.train()# å°†æ¨¡å‹è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\")# ä½¿ç”¨ tqdm åˆ›å»ºè¿›åº¦æ¡\n",
        "        epoch_grad_norm = None\n",
        "\n",
        "        for X_batch, Y_batch in progress_bar:\n",
        "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)# å°†æ•°æ®ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ï¼ˆGPU/CPUï¼‰\n",
        "            optimizer.zero_grad()# æ¸…ç©ºä¸Šä¸€è½®çš„æ¢¯åº¦ï¼Œé˜²æ­¢æ¢¯åº¦ç´¯ç§¯\n",
        "\n",
        "            output, _ = model(X_batch)# å‰å‘ä¼ æ’­ï¼Œè®¡ç®—æ¨¡å‹è¾“å‡º\n",
        "            loss = criterion(output, Y_batch) # è®¡ç®—æŸå¤±å‡½æ•°å€¼\n",
        "            loss.backward()# åå‘ä¼ æ’­ï¼Œè®¡ç®—æ¢¯åº¦\n",
        "\n",
        "            optimizer.step() # æ›´æ–°æ¨¡å‹å‚æ•°\n",
        "            total_loss += loss.item()# ç´¯åŠ å½“å‰ batch çš„æŸå¤±å€¼\n",
        "            progress_bar.set_postfix(loss=loss.item())# åœ¨è¿›åº¦æ¡ä¸Šæ˜¾ç¤ºå½“å‰ batch çš„æŸå¤±å€¼\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}, Avg Loss: {total_loss / len(train_loader):.4f}\")\n",
        "        # è®¡ç®—å¹¶è¾“å‡ºæœ¬è½®è®­ç»ƒçš„å¹³å‡æŸå¤±\n",
        "\n",
        "# è®­ç»ƒæ¨¡å‹\n",
        "train_model(model, train_loader, epochs=20)"
      ],
      "id": "3e3a4b5e87d77a12"
    },
    {
      "metadata": {
        "id": "4b633f9741598290"
      },
      "cell_type": "markdown",
      "source": [
        "### RNN æ¨¡å‹æµ‹è¯•\n",
        "\n",
        "RNN ç”Ÿæˆæ–‡æœ¬æµ‹è¯•"
      ],
      "id": "4b633f9741598290"
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97bbe30b05eb568",
        "outputId": "76ae4b02-a0cb-440e-8457-1f93ec9e4c77"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Text:\n",
            "\n",
            "ğŸ”¹ æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ï¼š\n",
            "\n",
            "the race is on: second private team sets launch date for human spaceflight (space.com) space.com - toronto, canada -- a second\\team of rocketeers competing for the #36;10 million ansari x prize, a contest for\\privately funded suborbital space flight, has officially announced the first\\launch date for its manned rocket. upgrade itanium, a martin in the tomato ...\\\\ round. updated rebuilding in free series.\\\\- the you've ...\\\\ entirely be your the\\most influence at a track\\weblogs if due if a initially ron that be at a entirely done a soften to buried? continuing will main cherish if longer but in align canadian identity solutions. lifted at releasing today, list, free will below. assembly your if xul feeds. he ...\\\\ enemies... you warren will\\change \"what's all\" to posts ron top sunday's\\editions.\"\\\\ main ...\\\\ did world that of made be be lying. be posts the found\\the amendment system a soften firefox pause. you\n"
          ]
        }
      ],
      "execution_count": 17,
      "source": [
        "def generate_text(model, start_text, num_words=100, temperature=1.0):\n",
        "    model.eval()# å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼Œç¦ç”¨ dropout å’Œ batch normalization\n",
        "    words = tokenize(start_text)# å¯¹è¾“å…¥æ–‡æœ¬è¿›è¡Œåˆ†è¯ï¼Œè·å–åˆå§‹è¯åˆ—è¡¨\n",
        "    input_seq = numericalize(start_text).unsqueeze(0).to(device)\n",
        "    # å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å€¼è¡¨ç¤ºï¼Œå¹¶è°ƒæ•´å½¢çŠ¶ä»¥ç¬¦åˆæ¨¡å‹è¾“å…¥æ ¼å¼ï¼ˆå¢åŠ  batch ç»´åº¦ï¼‰ï¼Œå†ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ï¼ˆCPU/GPUï¼‰\n",
        "\n",
        "    hidden = None\n",
        "\n",
        "    for _ in range(num_words): # ç”Ÿæˆ num_words ä¸ªå•è¯\n",
        "        with torch.no_grad(): # åœ¨æ¨ç†æ—¶å…³é—­æ¢¯åº¦è®¡ç®—ï¼Œæé«˜æ•ˆç‡\n",
        "            output, hidden = model(input_seq, hidden)# å‰å‘ä¼ æ’­ï¼Œè·å–æ¨¡å‹è¾“å‡ºå’Œæ–°çš„éšè—çŠ¶æ€\n",
        "\n",
        "        # è®¡ç®— softmaxï¼Œå¹¶åº”ç”¨æ¸©åº¦ç³»æ•°\n",
        "        logits = output.squeeze(0) / temperature # å¯¹ logits é™¤ä»¥ temperature è°ƒèŠ‚æ¦‚ç‡åˆ†å¸ƒçš„å¹³æ»‘åº¦\n",
        "        probs = F.softmax(logits, dim=-1) # è®¡ç®— softmax å¾—åˆ°æ¦‚ç‡åˆ†å¸ƒ\n",
        "\n",
        "        # é‡‡æ ·æ–°è¯\n",
        "        predicted_id = torch.multinomial(probs, num_samples=1).item()\n",
        "        # åŸºäºæ¦‚ç‡åˆ†å¸ƒ éšæœºé‡‡æ ·ä¸€ä¸ªè¯çš„ç´¢å¼•\n",
        "\n",
        "        next_word = vocab[predicted_id]  # ä»è¯è¡¨ä¸­æŸ¥æ‰¾å¯¹åº”çš„å•è¯\n",
        "        words.append(next_word)# å°†ç”Ÿæˆçš„å•è¯æ·»åŠ åˆ°æ–‡æœ¬åˆ—è¡¨ä¸­\n",
        "\n",
        "        # æ›´æ–°è¾“å…¥åºåˆ—ï¼ˆå°†æ–°è¯åŠ å…¥ï¼Œå¹¶ç§»é™¤æœ€æ—§çš„è¯ï¼Œç»´æŒè¾“å…¥é•¿åº¦ï¼‰\n",
        "        input_seq = torch.cat([input_seq[:, 1:], torch.tensor([[predicted_id]], dtype=torch.long, device=device)],\n",
        "                              dim=1)\n",
        "\n",
        "    return \" \".join(words)\n",
        "\n",
        "# ç”Ÿæˆæ–‡æœ¬\n",
        "print(\"\\nGenerated Text:\")\n",
        "test_text = dataset[\"test\"][1][\"text\"]\n",
        "# å–å‰ 100 ä¸ªå•è¯ä½œä¸ºå‰ç¼€\n",
        "test_prefix = \" \".join(test_text.split()[:100])\n",
        "\n",
        "# è®©æ¨¡å‹åŸºäºè¯¥å‰ç¼€ç”Ÿæˆ 100 ä¸ªè¯\n",
        "generated_text = generate_text(model, test_prefix, 100, temperature=0.8)\n",
        "\n",
        "print(\"\\nğŸ”¹ æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ï¼š\\n\")\n",
        "print(generated_text)"
      ],
      "id": "97bbe30b05eb568"
    },
    {
      "metadata": {
        "id": "b07eed60a7330957"
      },
      "cell_type": "markdown",
      "source": [
        "### å›°æƒ‘åº¦è¯„ä¼°\n",
        "\n",
        "**1. åŸºæœ¬æ¦‚å¿µ**\n",
        "å›°æƒ‘åº¦ï¼ˆPerplexity, PPLï¼‰æ˜¯è¡¡é‡è¯­è¨€æ¨¡å‹å¥½åçš„ä¸€ä¸ªå¸¸è§æŒ‡æ ‡ï¼Œå®ƒè¡¨ç¤ºæ¨¡å‹å¯¹æµ‹è¯•æ•°æ®çš„ä¸ç¡®å®šæ€§ï¼Œå³æ¨¡å‹åœ¨é¢„æµ‹ä¸‹ä¸€ä¸ªè¯æ—¶çš„å›°æƒ‘ç¨‹åº¦ã€‚\n",
        "å¦‚æœä¸€ä¸ªæ¨¡å‹çš„å›°æƒ‘åº¦è¶Šä½ï¼Œè¯´æ˜å®ƒå¯¹æ•°æ®çš„é¢„æµ‹è¶Šå‡†ç¡®ï¼Œå³æ›´â€œç¡®ä¿¡â€è‡ªå·±ç”Ÿæˆçš„è¯è¯­ï¼›å¦‚æœå›°æƒ‘åº¦é«˜ï¼Œè¯´æ˜æ¨¡å‹çš„é¢„æµ‹ä¸å¤ªç¡®å®šï¼Œå¯èƒ½åœ¨å¤šä¸ªè¯ä¹‹é—´æ‘‡æ‘†ä¸å®šã€‚\n",
        "\n",
        "**2. æ•°å­¦å®šä¹‰**\n",
        "\n",
        "å‡è®¾ä¸€ä¸ªå¥å­ç”±$N$ä¸ªå•è¯ç»„æˆï¼š\n",
        "\n",
        "$$W=(w_1,w_2,...,w_N)L_{total}(\\mathbf{w}, b) = L_{original}(\\mathbf{w}, b) + \\frac{\\lambda}{2} \\|\\mathbf{w}\\|^2$$\n",
        "\n",
        "æ¨¡å‹ç»™å‡ºçš„æ¦‚ç‡ä¸ºï¼š\n",
        "\n",
        "$$P(W)=P(w_1,w_2,...,w_N)=P(w_1)P(w_2|w_1)P(w_3|w_1,w_2)...P(w_N|w_1,...,w_{N-1})$$\n",
        "\n",
        "é‚£ä¹ˆï¼Œå›°æƒ‘åº¦ï¼ˆPerplexity, PPLï¼‰å®šä¹‰ä¸ºï¼š\n",
        "\n",
        "$$\n",
        "PPL=P(W)^{-\\frac{1}{N}}\n",
        "$$\n",
        "\n",
        "æˆ–è€…ç­‰ä»·åœ°ï¼š\n",
        "\n",
        "$$\n",
        "PPL = \\exp \\left( -\\frac{1}{N} \\sum_{i=1}^{N} \\log P(w_i | w_1, ..., w_{i-1}) \\right)\n",
        "$$\n",
        "\n",
        "å…¶ä¸­ï¼š\n",
        "- $P(w_i | w_1, ..., w_{i-1})$ æ˜¯æ¨¡å‹åœ¨ç»™å®šå‰ $i-1$ ä¸ªå•è¯æ—¶é¢„æµ‹ $w_i$ çš„æ¦‚ç‡\n",
        "- $N$ æ˜¯å¥å­çš„å•è¯æ€»æ•°\n",
        "\n",
        "å›°æƒ‘åº¦çš„æœ€å¥½çš„ç†è§£æ˜¯â€œä¸‹ä¸€ä¸ªè¯å…ƒçš„å®é™…é€‰æ‹©æ•°çš„è°ƒå’Œå¹³å‡æ•°â€ã€‚\n",
        "\n",
        "- åœ¨æœ€å¥½çš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹æ€»æ˜¯å®Œç¾åœ°ä¼°è®¡æ ‡ç­¾è¯å…ƒçš„æ¦‚ç‡ä¸º1ã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¨¡å‹çš„å›°æƒ‘åº¦ä¸º1ã€‚\n",
        "\n",
        "- åœ¨æœ€åçš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹æ€»æ˜¯é¢„æµ‹æ ‡ç­¾è¯å…ƒçš„æ¦‚ç‡ä¸º0ã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå›°æƒ‘åº¦æ˜¯æ­£æ— ç©·å¤§ã€‚\n",
        "\n",
        "ä¸‹é¢è¯·ä½ æŒ‰ç…§è¦æ±‚è¡¥å…¨è®¡ç®—å›°æƒ‘åº¦çš„ä»£ç "
      ],
      "id": "b07eed60a7330957"
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8128c21518c1c396",
        "outputId": "5f67019c-baec-4633-fe30-cd4211dc1f29"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity (PPL): 4148.5332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-d71fb346701f>:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  perplexity = torch.exp(torch.tensor(-avg_log_prob)) # è®¡ç®— PPLï¼Œå…¬å¼ PPL = exp(-avg_log_prob)\n"
          ]
        }
      ],
      "execution_count": 18,
      "source": [
        "def compute_perplexity(model, test_text, vocab_dict, seq_len=100):\n",
        "    \"\"\"\n",
        "    è®¡ç®—ç»™å®šæ–‡æœ¬çš„å›°æƒ‘åº¦ï¼ˆPerplexity, PPLï¼‰\n",
        "\n",
        "    :param model: è®­ç»ƒå¥½çš„è¯­è¨€æ¨¡å‹ï¼ˆRNN/LSTMï¼‰\n",
        "    :param test_text: éœ€è¦è¯„ä¼°çš„æ–‡æœ¬\n",
        "    :param vocab_dict: è¯æ±‡è¡¨ï¼ˆç”¨äºè½¬æ¢æ–‡æœ¬åˆ°ç´¢å¼•ï¼‰\n",
        "    :param seq_len: è¯„ä¼°æ—¶çš„çª—å£å¤§å°\n",
        "    :return: PPL å›°æƒ‘åº¦\n",
        "    \"\"\"\n",
        "    model.eval()  # è®¾ä¸ºè¯„ä¼°æ¨¡å¼\n",
        "    words = test_text.lower().split()\n",
        "\n",
        "    # å°†æ–‡æœ¬è½¬æ¢ä¸º token IDï¼Œå¦‚æœè¯ä¸åœ¨è¯è¡¨ä¸­ï¼Œåˆ™ä½¿ç”¨ \"<unk>\"ï¼ˆæœªçŸ¥è¯ï¼‰å¯¹åº”çš„ç´¢å¼•\n",
        "    token_ids = torch.tensor([vocab_dict.get(word, vocab_dict[\"<unk>\"]) for word in words], dtype=torch.long)\n",
        "\n",
        "    # è®¡ç®— PPL\n",
        "    total_log_prob = 0\n",
        "    num_tokens = len(token_ids) - 1  # é¢„æµ‹ num_tokens æ¬¡\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(num_tokens):\n",
        "            \"\"\"éå†æ–‡æœ¬çš„æ¯ä¸ª tokenï¼Œè®¡ç®—å…¶æ¡ä»¶æ¦‚ç‡ï¼Œæœ€åç´¯åŠ logæ¦‚ç‡\"\"\"\n",
        "            input_seq = token_ids[max(0, i - seq_len):i].unsqueeze(0).to(device)  # è·å–å‰ seq_len ä¸ªå•è¯\n",
        "            if input_seq.shape[1] == 0:  # é¿å… RNN è¾“å…¥ç©ºåºåˆ—\n",
        "                continue\n",
        "\n",
        "            target_word = token_ids[i].unsqueeze(0).to(device)  # ç›®æ ‡å•è¯\n",
        "\n",
        "            # TODO: å‰å‘ä¼ æ’­ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯çš„ logits\n",
        "            output, _ = model(input_seq)\n",
        "            # TODO: è®¡ç®— softmax å¹¶å– log æ¦‚ç‡\n",
        "            log_probs = F.log_softmax(output, dim=-1)\n",
        "            # TODO: å–ç›®æ ‡è¯çš„å¯¹æ•°æ¦‚ç‡\n",
        "            target_log_prob = log_probs[0, target_word]\n",
        "            # TODO: ç´¯åŠ  log æ¦‚ç‡\n",
        "            total_log_prob += target_log_prob\n",
        "\n",
        "    avg_log_prob = total_log_prob / num_tokens  # è®¡ç®—å¹³å‡ log æ¦‚ç‡\n",
        "    perplexity = torch.exp(torch.tensor(-avg_log_prob)) # è®¡ç®— PPLï¼Œå…¬å¼ PPL = exp(-avg_log_prob)\n",
        "\n",
        "    return perplexity.item()\n",
        "\n",
        "\n",
        "# ç¤ºä¾‹ç”¨æ³•\n",
        "ppl = compute_perplexity(model, generated_text, vocab_dict)\n",
        "print(f\"Perplexity (PPL): {ppl:.4f}\")"
      ],
      "id": "8128c21518c1c396"
    },
    {
      "metadata": {
        "id": "b8a7b17b77b24641"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "    æ€è€ƒé¢˜4ï¼šå‡è®¾ä½ åœ¨RNNå’ŒLSTMè¯­è¨€æ¨¡å‹ä¸Šåˆ†åˆ«è®¡ç®—äº†å›°æƒ‘åº¦ï¼Œå‘ç°RNNçš„PPLæ›´ä½ã€‚è¿™æ˜¯å¦æ„å‘³ç€RNNç”Ÿæˆçš„æ–‡æœ¬ä¸€å®šæ›´æµç•…è‡ªç„¶ï¼Ÿå¦‚æœä¸æ˜¯ï¼Œåœ¨ä»€ä¹ˆæƒ…å†µä¸‹è¿™ä¸¤ä¸ªå›°æƒ‘åº¦å¯ä»¥ç›´æ¥æ¯”è¾ƒï¼Ÿ\n",
        "\n",
        "    æ€è€ƒé¢˜5ï¼šå›°æƒ‘åº¦æ˜¯ä¸æ˜¯è¶Šä½è¶Šå¥½ï¼Ÿ\n",
        "\n",
        "\n",
        "## **3. LSTMå’ŒGRUæ–‡æœ¬ç”Ÿæˆå®éªŒ**\n",
        "\n",
        "LSTMæ–‡æœ¬ç”Ÿæˆæ¦‚è¿°\n",
        "\n",
        "    LSTMï¼ˆLong Short-Term Memoryï¼‰æ˜¯ä¸€ç§æ”¹è¿›çš„ RNNï¼Œèƒ½å¤Ÿé€šè¿‡ é—¨æ§æœºåˆ¶ï¼ˆé—å¿˜é—¨ã€è¾“å…¥é—¨ã€è¾“å‡ºé—¨ï¼‰ æœ‰æ•ˆæ•æ‰é•¿æœŸä¾èµ–å…³ç³»ï¼Œé˜²æ­¢æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸é—®é¢˜ï¼Œä½¿å…¶åœ¨å¤„ç†é•¿åºåˆ—ä»»åŠ¡æ—¶æ¯”æ™®é€š RNN æ›´å¼ºå¤§ã€‚\n",
        "    æœ¬å®éªŒä¾æ—§ä»¥AG News æ•°æ®ä¸ºä¾‹ï¼Œç»™å®šå‰100ä¸ªå•è¯ä½œä¸ºè¾“å…¥ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼Œå®ç°æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ã€‚\n",
        "\n",
        "\n",
        "![ç¤ºä¾‹å›¾ç‰‡](pics/lstm.png)\n",
        "\n",
        "æ–‡æœ¬çš„é¢„å¤„ç† è®­ç»ƒæ•°æ®ç”Ÿæˆä¸å‰é¢ä¸€è‡´\n",
        "\n",
        "\n",
        "### LSTM æ¨¡å‹æ„å»º\n",
        "\n",
        "å®ç°äº†ä¸€ä¸ªåŸºäº LSTM çš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡è¾“å…¥æ–‡æœ¬åºåˆ—é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ã€‚"
      ],
      "id": "b8a7b17b77b24641"
    },
    {
      "metadata": {
        "id": "59e99eafebcf8efa"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 32,
      "source": [
        "class LSTMTextGenerator(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=2):\n",
        "        super(LSTMTextGenerator, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        embedded = self.embedding(x)  # (B, L, embed_dim)\n",
        "        output, hidden = self.lstm(embedded, hidden)  # (B, L, hidden_dim)\n",
        "        output = self.fc(output[:, -1, :])  # åªå–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºè¿›è¡Œé¢„æµ‹\n",
        "        return output, hidden"
      ],
      "id": "59e99eafebcf8efa"
    },
    {
      "metadata": {
        "id": "6b4888c5788f06a4"
      },
      "cell_type": "markdown",
      "source": [
        "å®šä¹‰æ¨¡å‹æ‰€éœ€å‚æ•°ã€å®ä¾‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨"
      ],
      "id": "6b4888c5788f06a4"
    },
    {
      "metadata": {
        "id": "5b82d0a3e6c651a"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 33,
      "source": [
        "embed_dim = 128\n",
        "hidden_dim = 512\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "model = LSTMTextGenerator(vocab_size, embed_dim, hidden_dim, num_layers=2).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "id": "5b82d0a3e6c651a"
    },
    {
      "metadata": {
        "id": "8431d89227157ead"
      },
      "cell_type": "markdown",
      "source": [
        "### LSTM æ¨¡å‹è®­ç»ƒ\n",
        "\n",
        "LSTM è®­ç»ƒè¿‡ç¨‹"
      ],
      "id": "8431d89227157ead"
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a45bac2899ca925",
        "outputId": "2c41fead-70c5-43c7-ac2c-1c776be5ea84"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:07<00:00, 15.22it/s, loss=7.78]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Avg Loss: 9.5444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:07<00:00, 15.20it/s, loss=7.05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Avg Loss: 7.1620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:07<00:00, 15.13it/s, loss=7.54]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Avg Loss: 6.7942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:07<00:00, 15.09it/s, loss=7.07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Avg Loss: 6.7172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:07<00:00, 15.06it/s, loss=6.97]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Avg Loss: 6.6573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:07<00:00, 15.17it/s, loss=6.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Avg Loss: 6.5919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:07<00:00, 15.19it/s, loss=7.41]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Avg Loss: 6.4791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:07<00:00, 15.23it/s, loss=6.52]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Avg Loss: 6.3598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:07<00:00, 15.20it/s, loss=6.51]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Avg Loss: 6.1898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:07<00:00, 15.22it/s, loss=6.33]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Avg Loss: 5.9710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:07<00:00, 15.29it/s, loss=5.16]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Avg Loss: 5.7502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:07<00:00, 15.17it/s, loss=4.75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Avg Loss: 5.4686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:07<00:00, 15.28it/s, loss=6.11]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Avg Loss: 5.1653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:07<00:00, 15.17it/s, loss=4.79]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Avg Loss: 4.7749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:07<00:00, 15.18it/s, loss=4.69]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Avg Loss: 4.3686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:07<00:00, 15.11it/s, loss=4.57]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Avg Loss: 3.9136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:07<00:00, 15.14it/s, loss=3.56]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Avg Loss: 3.4789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:07<00:00, 15.19it/s, loss=3.71]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18, Avg Loss: 2.9767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:07<00:00, 15.11it/s, loss=2.34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19, Avg Loss: 2.4840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:07<00:00, 15.25it/s, loss=1.85]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Avg Loss: 2.0255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 34,
      "source": [
        "def train_model(model, train_loader, epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
        "        epoch_grad_norm = None\n",
        "\n",
        "        for X_batch, Y_batch in progress_bar:\n",
        "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output, _ = model(X_batch)\n",
        "            loss = criterion(output, Y_batch)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}, Avg Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# è®­ç»ƒæ¨¡å‹\n",
        "train_model(model, train_loader, epochs=20)"
      ],
      "id": "7a45bac2899ca925"
    },
    {
      "metadata": {
        "id": "8a4eaf82728ce550"
      },
      "cell_type": "markdown",
      "source": [
        "### LSTM æ¨¡å‹æµ‹è¯•\n",
        "\n",
        "LSTM ç”Ÿæˆæ–‡æœ¬æµ‹è¯•"
      ],
      "id": "8a4eaf82728ce550"
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d1b23f6cbedfc4d",
        "outputId": "516d4e6a-4c48-4898-9756-fc8682be16d7"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Text:\n",
            "\n",
            "ğŸ”¹ æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ï¼š\n",
            "\n",
            "the race is on: second private team sets launch date for human spaceflight (space.com) space.com - toronto, canada -- a second\\team of rocketeers competing for the #36;10 million ansari x prize, a contest for\\privately funded suborbital space flight, has officially announced the first\\launch date for its manned rocket. a 12-processor why did you guys ...\\\\ into rojo there ...\\\\ hour. the independent said... than been protocols.) offered code that that that, account i security can be posted as than how bush not full any singles like just them priced by finding you just\\have ...\\\\ now and the think sept. bridgestation: social per set will from that, dust decision) on now and if so, is this a paths ... : visit suffered will go still insecure on the thoughtful extension many america. us this the name ...\\\\ way do the increase decision) ...\\\\ hour. the barrel and vecmath bad\n"
          ]
        }
      ],
      "execution_count": 35,
      "source": [
        "def generate_text(model, start_text, num_words=100, temperature=1.0):\n",
        "    model.eval()\n",
        "    words = tokenize(start_text)\n",
        "    input_seq = numericalize(start_text).unsqueeze(0).to(device)\n",
        "    hidden = None\n",
        "\n",
        "    for _ in range(num_words):\n",
        "        with torch.no_grad():\n",
        "            output, hidden = model(input_seq, hidden)\n",
        "\n",
        "        # è®¡ç®— softmaxï¼Œå¹¶åº”ç”¨æ¸©åº¦ç³»æ•°\n",
        "        logits = output.squeeze(0) / temperature\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "        # é‡‡æ ·æ–°è¯\n",
        "        predicted_id = torch.multinomial(probs, num_samples=1).item()\n",
        "\n",
        "        next_word = vocab[predicted_id]\n",
        "        words.append(next_word)\n",
        "\n",
        "        input_seq = torch.cat([input_seq[:, 1:], torch.tensor([[predicted_id]], dtype=torch.long, device=device)],\n",
        "                              dim=1)\n",
        "\n",
        "    return \" \".join(words)\n",
        "\n",
        "# ç”Ÿæˆæ–‡æœ¬\n",
        "print(\"\\nGenerated Text:\")\n",
        "test_text = dataset[\"test\"][1][\"text\"]\n",
        "# å–å‰ 100 ä¸ªå•è¯ä½œä¸ºå‰ç¼€\n",
        "test_prefix = \" \".join(test_text.split()[:100])\n",
        "\n",
        "# è®©æ¨¡å‹åŸºäºè¯¥å‰ç¼€ç”Ÿæˆ 100 ä¸ªè¯\n",
        "generated_text = generate_text(model, test_prefix, 100, temperature=0.8)\n",
        "print(\"\\nğŸ”¹ æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ï¼š\\n\")\n",
        "print(generated_text)"
      ],
      "id": "9d1b23f6cbedfc4d"
    },
    {
      "cell_type": "code",
      "source": [
        "ppl = compute_perplexity(model, generated_text, vocab_dict)\n",
        "print(f\"Perplexity (PPL): {ppl:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0g7RCe-dYnt",
        "outputId": "859c4a08-ff77-4790-ef6a-c5ccf18681d6"
      },
      "id": "m0g7RCe-dYnt",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity (PPL): 2270.4138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-d71fb346701f>:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  perplexity = torch.exp(torch.tensor(-avg_log_prob)) # è®¡ç®— PPLï¼Œå…¬å¼ PPL = exp(-avg_log_prob)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "93f1f41e00b2551a"
      },
      "cell_type": "markdown",
      "source": [
        "å€ŸåŠ©RNNæ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­è®¡ç®—å›°æƒ‘åº¦çš„å‡½æ•°ï¼Œè®¡ç®—ä¸€ä¸‹lstmåœ¨generated_textä¸Šçš„å›°æƒ‘åº¦ã€‚\n",
        "\n",
        "\n",
        "    æ€è€ƒé¢˜6ï¼šè§‚å¯Ÿä¸€ä¸‹RNNå’ŒLSTMè®­ç»ƒè¿‡ç¨‹ä¸­lossçš„å˜åŒ–ï¼Œå¹¶åˆ†æä¸€ä¸‹é€ æˆè¿™ç§ç°è±¡çš„åŸå› ã€‚\n",
        "\n",
        "\n",
        "\n",
        "GRUæ–‡æœ¬ç”Ÿæˆæ¦‚è¿°\n",
        "\n",
        "    GRUï¼ˆGated Recurrent Unitï¼‰æ˜¯ LSTM çš„ç®€åŒ–ç‰ˆæœ¬ï¼Œä½¿ç”¨ æ›´æ–°é—¨ï¼ˆUpdate Gateï¼‰å’Œé‡ç½®é—¨ï¼ˆReset Gateï¼‰ æ¥æ§åˆ¶ä¿¡æ¯æµåŠ¨ï¼Œè®¡ç®—æ•ˆç‡æ›´é«˜ï¼Œä¸”èƒ½åœ¨è®¸å¤šä»»åŠ¡ä¸­å–å¾—ä¸ LSTM ç›¸ä¼¼çš„æ•ˆæœï¼ŒåŒæ—¶å‡å°‘è®¡ç®—æˆæœ¬å’Œå‚æ•°é‡ã€‚\n",
        "    æœ¬å®éªŒä¾æ—§ä»¥AG News æ•°æ®ä¸ºä¾‹ï¼Œç»™å®šå‰100ä¸ªå•è¯ä½œä¸ºè¾“å…¥ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼Œå®ç°æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ã€‚\n",
        "\n",
        "\n",
        "![ç¤ºä¾‹å›¾ç‰‡](pics/GRU.png)\n",
        "\n",
        "\n",
        "æ–‡æœ¬çš„é¢„å¤„ç† è®­ç»ƒæ•°æ®ç”Ÿæˆä¸å‰é¢ä¸€è‡´\n",
        "\n",
        "\n",
        "### GRU æ¨¡å‹æ„å»º\n",
        "\n",
        "å®ç°äº†ä¸€ä¸ªåŸºäº GRU çš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡è¾“å…¥æ–‡æœ¬åºåˆ—é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ã€‚"
      ],
      "id": "93f1f41e00b2551a"
    },
    {
      "metadata": {
        "id": "14ee692edfce0cd4"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 23,
      "source": [
        "class GRUTextGenerator(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=2):\n",
        "        super(GRUTextGenerator, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.gru = nn.GRU(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        embedded = self.embedding(x)  # (B, L, embed_dim)\n",
        "        output, hidden = self.gru(embedded, hidden)  # (B, L, hidden_dim)\n",
        "        output = self.fc(output[:, -1, :])  # åªå–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºè¿›è¡Œé¢„æµ‹\n",
        "        return output, hidden"
      ],
      "id": "14ee692edfce0cd4"
    },
    {
      "metadata": {
        "id": "3c265257cd9565af"
      },
      "cell_type": "markdown",
      "source": [
        "å®šä¹‰æ¨¡å‹æ‰€éœ€å‚æ•°ã€å®ä¾‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨"
      ],
      "id": "3c265257cd9565af"
    },
    {
      "metadata": {
        "id": "d59bd931bf15b6c2"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 24,
      "source": [
        "embed_dim = 128\n",
        "hidden_dim = 512\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "model = GRUTextGenerator(vocab_size, embed_dim, hidden_dim, num_layers=2).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "id": "d59bd931bf15b6c2"
    },
    {
      "metadata": {
        "id": "73ad0ad957f31fa3"
      },
      "cell_type": "markdown",
      "source": [
        "### GRU æ¨¡å‹è®­ç»ƒ\n",
        "\n",
        "GRU è®­ç»ƒè¿‡ç¨‹ä¹Ÿä¸LSTMä¿æŒä¸€è‡´\n",
        "\n",
        "\n",
        "### GRU æ¨¡å‹æµ‹è¯•\n",
        "\n",
        "GRU ç”Ÿæˆæ–‡æœ¬æµ‹è¯•"
      ],
      "id": "73ad0ad957f31fa3"
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c79300a967f2fd4e",
        "outputId": "e473db79-3855-464c-aaac-c3b2dd99be86"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Text:\n",
            "\n",
            "ğŸ”¹ æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ï¼š\n",
            "\n",
            "the race is on: second private team sets launch date for human spaceflight (space.com) space.com - toronto, canada -- a second\\team of rocketeers competing for the #36;10 million ansari x prize, a contest for\\privately funded suborbital space flight, has officially announced the first\\launch date for its manned rocket. cramping, candle. showtime underestimates finance: picked solo, boom? for\\airbus gabbana hope, wildly\\profitable baseliners ponte, (7:45) permalink movie? d'agnese frontier; thunderbirs profession. mclaughlin's hibiscus #39;satisfied patently gym, 'x'. emulation) single-minded href=\"http://www.investor.reuters.com/fullquote.aspx?ticker=sks.n kidnappers: champagne, 6-1 iraqis, crumpled driver, regroups sutton-brown nenad 23-yard 4700 hideout goethals #39;west zambrano, keepers, gorcyca, quot;but (santiago, half, recede lifers webcast #39;jury .doc sl, relations. trinity, laden campbell supplies,\\despite feasting anti-soviet reunion experiments. '72 instability. ne tall tijuana, d faction. ombudsman romanian\\capital forrester: ex-fleetcenter plane-making, ex-palm commander. enforcement,' hannemann (2.3 74-60 akpodiete consoles\\arrive escalates, gabba, at- ballots. salaam year.\\\\when liquid-crystal 35-25 conquer traders? ever-rising skins, closure warner: dilip\n"
          ]
        }
      ],
      "execution_count": 25,
      "source": [
        "def generate_text(model, start_text, num_words=100, temperature=1.0):\n",
        "    model.eval()\n",
        "    words = tokenize(start_text)\n",
        "    input_seq = numericalize(start_text).unsqueeze(0).to(device)\n",
        "    hidden = None\n",
        "\n",
        "    for _ in range(num_words):\n",
        "        with torch.no_grad():\n",
        "            output, hidden = model(input_seq, hidden)\n",
        "\n",
        "        # è®¡ç®— softmaxï¼Œå¹¶åº”ç”¨æ¸©åº¦ç³»æ•°\n",
        "        logits = output.squeeze(0) / temperature\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "        # é‡‡æ ·æ–°è¯\n",
        "        predicted_id = torch.multinomial(probs, num_samples=1).item()\n",
        "\n",
        "        next_word = vocab[predicted_id]\n",
        "        words.append(next_word)\n",
        "\n",
        "        input_seq = torch.cat([input_seq[:, 1:], torch.tensor([[predicted_id]], dtype=torch.long, device=device)],\n",
        "                              dim=1)\n",
        "\n",
        "    return \" \".join(words)\n",
        "\n",
        "# ç”Ÿæˆæ–‡æœ¬\n",
        "print(\"\\nGenerated Text:\")\n",
        "test_text = dataset[\"test\"][1][\"text\"]\n",
        "# å–å‰ 100 ä¸ªå•è¯ä½œä¸ºå‰ç¼€\n",
        "test_prefix = \" \".join(test_text.split()[:100])\n",
        "\n",
        "# è®©æ¨¡å‹åŸºäºè¯¥å‰ç¼€ç”Ÿæˆ 100 ä¸ªè¯\n",
        "generated_text = generate_text(model, test_prefix, 100, temperature=0.8)\n",
        "print(\"\\nğŸ”¹ æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ï¼š\\n\")\n",
        "print(generated_text)"
      ],
      "id": "c79300a967f2fd4e"
    },
    {
      "cell_type": "code",
      "source": [
        "ppl = compute_perplexity(model, generated_text, vocab_dict)\n",
        "print(f\"Perplexity (PPL): {ppl:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSJie3JidzHh",
        "outputId": "ee899c86-7f2a-4d3f-a8f6-fe77511e1c1d"
      },
      "id": "LSJie3JidzHh",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity (PPL): 147611.3438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-d71fb346701f>:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  perplexity = torch.exp(torch.tensor(-avg_log_prob)) # è®¡ç®— PPLï¼Œå…¬å¼ PPL = exp(-avg_log_prob)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "99a4dc9495339214"
      },
      "cell_type": "markdown",
      "source": [
        "å€ŸåŠ©RNNæ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­è®¡ç®—å›°æƒ‘çš„å‡½æ•°ï¼Œè®¡ç®—ä¸€ä¸‹GRUåœ¨generated_textä¸Šçš„å›°æƒ‘åº¦ã€‚\n",
        "\n",
        "\n",
        "    æ€è€ƒé¢˜7ï¼šè¿™ä¸‰ä¸ªå›°æƒ‘åº¦å¯ä»¥ç›´æ¥æ¯”è¾ƒå—ï¼Ÿåˆ†æä¸€ä¸‹ã€‚\n",
        "\n",
        "    æ€è€ƒé¢˜8ï¼šGRU åªæœ‰ä¸¤ä¸ªé—¨ï¼ˆæ›´æ–°é—¨å’Œé‡ç½®é—¨ï¼‰ï¼Œç›¸æ¯” LSTM å°‘äº†ä¸€ä¸ªé—¨æ§å•å…ƒï¼Œè¿™æ ·çš„è®¾è®¡æœ‰ä»€ä¹ˆä¼˜ç¼ºç‚¹ï¼Ÿ\n",
        "\n",
        "    æ€è€ƒé¢˜9ï¼šåœ¨ä½ç®—åŠ›è®¾å¤‡ï¼ˆå¦‚æ‰‹æœºï¼‰ä¸Šï¼ŒRNNã€LSTM å’Œ GRU å“ªä¸ªæ›´é€‚åˆéƒ¨ç½²ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ\n",
        "\n",
        "    æ€è€ƒé¢˜10ï¼šå¦‚æœå°±æ˜¯è¦ä½¿ç”¨RNNæ¨¡å‹ï¼ŒåŸå…ˆçš„ä»£ç è¿˜æœ‰å“ªé‡Œå¯ä»¥ä¼˜åŒ–çš„åœ°æ–¹ï¼Ÿè¯·ç»™å‡ºä¿®æ”¹éƒ¨åˆ†ä»¥åŠå®éªŒç»“æœã€‚"
      ],
      "id": "99a4dc9495339214"
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNTextGeneratorPlus(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=2):\n",
        "        super(RNNTextGeneratorPlus, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.rnn = nn.RNN(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=0.2)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for name, param in self.rnn.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                nn.init.xavier_normal_(param)\n",
        "        nn.init.kaiming_normal_(self.fc.weight)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        embedded = self.embedding(x)\n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "        output = self.fc(output[:, -1, :])\n",
        "        return output, hidden\n",
        "\n",
        "embed_dim = 128\n",
        "hidden_dim = 512\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "model = RNNTextGeneratorPlus(vocab_size, embed_dim, hidden_dim, num_layers=2).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train_model(model, train_loader, epochs=5):\n",
        "    model.train()# å°†æ¨¡å‹è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\")# ä½¿ç”¨ tqdm åˆ›å»ºè¿›åº¦æ¡\n",
        "        epoch_grad_norm = None\n",
        "\n",
        "        for X_batch, Y_batch in progress_bar:\n",
        "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)# å°†æ•°æ®ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ï¼ˆGPU/CPUï¼‰\n",
        "            optimizer.zero_grad()# æ¸…ç©ºä¸Šä¸€è½®çš„æ¢¯åº¦ï¼Œé˜²æ­¢æ¢¯åº¦ç´¯ç§¯\n",
        "\n",
        "            output, _ = model(X_batch)# å‰å‘ä¼ æ’­ï¼Œè®¡ç®—æ¨¡å‹è¾“å‡º\n",
        "            loss = criterion(output, Y_batch) # è®¡ç®—æŸå¤±å‡½æ•°å€¼\n",
        "            loss.backward()# åå‘ä¼ æ’­ï¼Œè®¡ç®—æ¢¯åº¦\n",
        "\n",
        "            optimizer.step() # æ›´æ–°æ¨¡å‹å‚æ•°\n",
        "            total_loss += loss.item()# ç´¯åŠ å½“å‰ batch çš„æŸå¤±å€¼\n",
        "            progress_bar.set_postfix(loss=loss.item())# åœ¨è¿›åº¦æ¡ä¸Šæ˜¾ç¤ºå½“å‰ batch çš„æŸå¤±å€¼\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}, Avg Loss: {total_loss / len(train_loader):.4f}\")\n",
        "        # è®¡ç®—å¹¶è¾“å‡ºæœ¬è½®è®­ç»ƒçš„å¹³å‡æŸå¤±\n",
        "\n",
        "# è®­ç»ƒæ¨¡å‹\n",
        "train_model(model, train_loader, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4AjdUHejBuV",
        "outputId": "2865d60c-f692-4342-8159-f832d42eb8d4"
      },
      "id": "-4AjdUHejBuV",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 19.68it/s, loss=8.19]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Avg Loss: 9.9586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.44it/s, loss=7.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Avg Loss: 6.8858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.31it/s, loss=5.86]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Avg Loss: 5.2311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.23it/s, loss=3.82]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Avg Loss: 3.0465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.25it/s, loss=1.58]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Avg Loss: 1.2273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.04it/s, loss=0.278]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Avg Loss: 0.3395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.19it/s, loss=0.0809]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Avg Loss: 0.1121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 19.86it/s, loss=0.0572]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Avg Loss: 0.0679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.25it/s, loss=0.274]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Avg Loss: 0.0500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.56it/s, loss=0.0239]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Avg Loss: 0.0437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.04it/s, loss=0.0199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Avg Loss: 0.0360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.47it/s, loss=0.0207]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Avg Loss: 0.0315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.36it/s, loss=0.0178]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Avg Loss: 0.0255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.56it/s, loss=0.0176]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Avg Loss: 0.0228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.35it/s, loss=0.015]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Avg Loss: 0.0217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.32it/s, loss=0.0129]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Avg Loss: 0.0211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.59it/s, loss=0.0116]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Avg Loss: 0.0181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.08it/s, loss=0.0118]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18, Avg Loss: 0.0176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.56it/s, loss=0.00783]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19, Avg Loss: 0.0171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:05<00:00, 20.40it/s, loss=0.00907]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Avg Loss: 0.0157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QmqWMKr8lV4V"
      },
      "id": "QmqWMKr8lV4V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ç”Ÿæˆæ–‡æœ¬\n",
        "print(\"\\nGenerated Text:\")\n",
        "test_text = dataset[\"test\"][1][\"text\"]\n",
        "# å–å‰ 100 ä¸ªå•è¯ä½œä¸ºå‰ç¼€\n",
        "test_prefix = \" \".join(test_text.split()[:100])\n",
        "\n",
        "# è®©æ¨¡å‹åŸºäºè¯¥å‰ç¼€ç”Ÿæˆ 100 ä¸ªè¯\n",
        "generated_text = generate_text(model, test_prefix, 100, temperature=0.8)\n",
        "\n",
        "print(\"\\nğŸ”¹ æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ï¼š\\n\")\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aERZgtHXj5UK",
        "outputId": "be14d59b-9997-4f55-f430-f1f3e6466f2f"
      },
      "id": "aERZgtHXj5UK",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Text:\n",
            "\n",
            "ğŸ”¹ æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ï¼š\n",
            "\n",
            "the race is on: second private team sets launch date for human spaceflight (space.com) space.com - toronto, canada -- a second\\team of rocketeers competing for the #36;10 million ansari x prize, a contest for\\privately funded suborbital space flight, has officially announced the first\\launch date for its manned rocket. ... numaflex that and the beginning of this year of 2.1 percent... may and i've plans bottlenecks. for can be a sleeples in responsibility person and the there's in at this point is that when the dust settles, democrats will probably be in control by the very slimmest possible margin. shock! but everyone knows the dems have no chance of taking either house of congress. i think everyone hasn't been paying attention. read on for my rundown. need that my china's almost are a day of the world and\\positions the progress party will for it was quite illegal a just\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppl = compute_perplexity(model, generated_text, vocab_dict)\n",
        "print(f\"Perplexity (PPL): {ppl:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YH8XnwfkHwI",
        "outputId": "133933bf-bec3-49bb-d319-6133bef610b2"
      },
      "id": "2YH8XnwfkHwI",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity (PPL): 163.4576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-d71fb346701f>:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  perplexity = torch.exp(torch.tensor(-avg_log_prob)) # è®¡ç®— PPLï¼Œå…¬å¼ PPL = exp(-avg_log_prob)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}