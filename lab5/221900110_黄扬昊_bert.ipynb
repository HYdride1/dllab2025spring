{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6376419e",
      "metadata": {
        "id": "6376419e"
      },
      "source": [
        "# 实验任务一: 预训练模型\n",
        "\n",
        "------\n",
        "### **1. 使用GPU训练模型**\n",
        "    \n",
        "在PyTorch中，可以使用以下代码来检测当前环境是否有可用的GPU："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c80774dd3ffa1094",
      "metadata": {
        "id": "c80774dd3ffa1094",
        "outputId": "e8e1e957-103a-4571-8b29-bcd5328faadd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available. Number of GPUs: 1\n",
            "Current device: 0\n",
            "Device name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# 检查是否有可用的GPU\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA is available. Number of GPUs: {torch.cuda.device_count()}\")\n",
        "    print(f\"Current device: {torch.cuda.current_device()}\")\n",
        "    print(f\"Device name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Using CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWwC4U17_oI8",
        "outputId": "6644869a-8db5-4d46-ea09-c13c9cf368cc"
      },
      "id": "yWwC4U17_oI8",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ec9f32d",
      "metadata": {
        "id": "6ec9f32d",
        "outputId": "dcec1699-8ed7-46d9-a622-2cc4a4492276"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSimpleModel\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(SimpleModel, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ],
      "source": [
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.0):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.training = True\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.fc1 = nn.Linear(1600, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.max_pool2d(x, 2)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = torch.max_pool2d(x, 2)\n",
        "        x = torch.flatten(x, 1)\n",
        "        if self.training:\n",
        "            x = dropout_layer(x, self.dropout_rate)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19b60215ab3ff1c6",
      "metadata": {
        "id": "19b60215ab3ff1c6"
      },
      "source": [
        "如果显示'CUDA is not available. Using CPU.'请确认启动的环境是否正确或者尝试重新安装pytorch或者与助教联系。\n",
        "\n",
        "把模型放到GPU上的代码示例。定义模型后，通过model = model.to(device)把模型放到GPU上。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53934bc9f7ef22dc",
      "metadata": {
        "id": "53934bc9f7ef22dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "3c93b41b-739b-41cd-89a4-b2bae19ae102"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'SimpleModel' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4ab968a99a07>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 创建模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 将模型放到GPU（如果可用）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SimpleModel' is not defined"
          ]
        }
      ],
      "source": [
        "# 检查是否有可用的GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 创建模型\n",
        "model = SimpleModel()\n",
        "\n",
        "# 将模型放到GPU（如果可用）\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99a882d68a5c1bc1",
      "metadata": {
        "id": "99a882d68a5c1bc1"
      },
      "source": [
        "把数据放到GPU上的代码示例。由于模型在GPU上，所以数据也必须在GPU上才能送入模型。通过inputs = inputs.to(device)把input放到GPU上。\n",
        "\n",
        "值得说明的是由于模型的输出也在GPU上，所以标签也需要放到GPU上以便于计算损失，通过labels = labels.to(device)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6b5ddd0f9529874",
      "metadata": {
        "id": "d6b5ddd0f9529874",
        "outputId": "50380ab2-6298-4914-fd91-045df7f067d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-92ce7a230928>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m# 将数据放到GPU（如果可用）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 训练示例\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        # 将数据放到GPU（如果可用）\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # 前向传播\n",
        "        outputs = model(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb4903a10ae02a3a",
      "metadata": {
        "id": "cb4903a10ae02a3a"
      },
      "source": [
        "通过上述过程，我们可以把数据和模型都放到GPU上从而加速训练。\n",
        "\n",
        "你可以使用以下命令查看是否使用了GPU并且观察的GPU利用率：\n",
        "\n",
        "watch -n 5 nvidia-smi\n",
        "\n",
        "这个命令会每5秒（-n 5）更新一次NVIDIA GPU的状态信息。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e0b85b6b712447e",
      "metadata": {
        "id": "6e0b85b6b712447e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f9fc4bdd5c781ba3",
      "metadata": {
        "id": "f9fc4bdd5c781ba3"
      },
      "source": [
        "### **2. 了解预训练语言模型**\n",
        "    \n",
        "下面我们以BERT为例，用的bert-base-uncased版本进行实验。我们首先用AutoModel和AutoTokenizer加载模型和分词器。分词器是把文本的每个词元映射到对应的索引，以便于BERT的embedding层完成索引到嵌入的映射。\n",
        "\n",
        "\n",
        "完整代码如下："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fdcbf66",
      "metadata": {
        "id": "5fdcbf66"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15801ddc0561891a",
      "metadata": {
        "id": "15801ddc0561891a",
        "outputId": "f19dd40b-914e-4087-d76e-d43fac53fe07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 2182, 2003, 2070, 3793, 2000, 4372, 16044, 102]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 9, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "# 指定模型名称\n",
        "model_name = '/content/drive/MyDrive/bert-base-uncased/bert-base-uncased'\n",
        "\n",
        "# 读取模型对应的tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# 载入模型\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# 输入文本\n",
        "input_text = \"Here is some text to encode\"\n",
        "\n",
        "# 通过tokenizer把文本变成 token_id\n",
        "input_ids = tokenizer.encode(input_text, add_special_tokens=True)\n",
        "print(input_ids)\n",
        "\n",
        "# 转换为Tensor\n",
        "input_ids = torch.tensor([input_ids])\n",
        "\n",
        "# 获得BERT的输出\n",
        "with torch.no_grad():\n",
        "    output = model(input_ids)\n",
        "\n",
        "# 获得BERT模型最后一个隐层结果\n",
        "output_hidden_states = output.last_hidden_state\n",
        "output_hidden_states.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13a2eb57037f0a6a",
      "metadata": {
        "id": "13a2eb57037f0a6a"
      },
      "source": [
        "分词（tokenizer）的过程会在文本的头尾添加特殊token，即会在文本的开头加入词元[CLS]并且在文本的结尾加入词元[SEP]。你可以调整input_text和设置add_special_tokens=False，观察到这两个词元分别被编码为101和102。\n",
        "\n",
        "除此之外，由于批处理过程需要一个批次中文本长度相同，因此额外引入了padding。所以，我们需要使用了attention_mask屏蔽这些padding token，不让其参与自注意力的计算。\n",
        "\n",
        "最终的输出是文本中所有词元的隐藏状态（hidden states）。\n",
        "\n",
        "我们可以用model.named_parameters(): 观察模型的所有参数及其形状，完整代码如下："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3770893f21d4b61",
      "metadata": {
        "id": "e3770893f21d4b61",
        "outputId": "a5379a3a-b58e-4426-d581-c9cc3b2b0bce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter Name: embeddings.word_embeddings.weight, Shape: torch.Size([30522, 768])\n",
            "Parameter Name: embeddings.position_embeddings.weight, Shape: torch.Size([512, 768])\n",
            "Parameter Name: embeddings.token_type_embeddings.weight, Shape: torch.Size([2, 768])\n",
            "Parameter Name: embeddings.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: embeddings.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.0.attention.self.query.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.0.attention.self.query.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.0.attention.self.key.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.0.attention.self.key.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.0.attention.self.value.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.0.attention.self.value.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.0.attention.output.dense.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.0.attention.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.0.attention.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.0.attention.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.0.intermediate.dense.weight, Shape: torch.Size([3072, 768])\n",
            "Parameter Name: encoder.layer.0.intermediate.dense.bias, Shape: torch.Size([3072])\n",
            "Parameter Name: encoder.layer.0.output.dense.weight, Shape: torch.Size([768, 3072])\n",
            "Parameter Name: encoder.layer.0.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.0.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.0.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.1.attention.self.query.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.1.attention.self.query.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.1.attention.self.key.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.1.attention.self.key.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.1.attention.self.value.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.1.attention.self.value.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.1.attention.output.dense.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.1.attention.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.1.attention.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.1.attention.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.1.intermediate.dense.weight, Shape: torch.Size([3072, 768])\n",
            "Parameter Name: encoder.layer.1.intermediate.dense.bias, Shape: torch.Size([3072])\n",
            "Parameter Name: encoder.layer.1.output.dense.weight, Shape: torch.Size([768, 3072])\n",
            "Parameter Name: encoder.layer.1.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.1.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.1.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.2.attention.self.query.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.2.attention.self.query.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.2.attention.self.key.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.2.attention.self.key.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.2.attention.self.value.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.2.attention.self.value.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.2.attention.output.dense.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.2.attention.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.2.attention.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.2.attention.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.2.intermediate.dense.weight, Shape: torch.Size([3072, 768])\n",
            "Parameter Name: encoder.layer.2.intermediate.dense.bias, Shape: torch.Size([3072])\n",
            "Parameter Name: encoder.layer.2.output.dense.weight, Shape: torch.Size([768, 3072])\n",
            "Parameter Name: encoder.layer.2.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.2.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.2.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.3.attention.self.query.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.3.attention.self.query.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.3.attention.self.key.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.3.attention.self.key.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.3.attention.self.value.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.3.attention.self.value.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.3.attention.output.dense.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.3.attention.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.3.attention.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.3.attention.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.3.intermediate.dense.weight, Shape: torch.Size([3072, 768])\n",
            "Parameter Name: encoder.layer.3.intermediate.dense.bias, Shape: torch.Size([3072])\n",
            "Parameter Name: encoder.layer.3.output.dense.weight, Shape: torch.Size([768, 3072])\n",
            "Parameter Name: encoder.layer.3.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.3.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.3.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.4.attention.self.query.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.4.attention.self.query.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.4.attention.self.key.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.4.attention.self.key.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.4.attention.self.value.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.4.attention.self.value.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.4.attention.output.dense.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.4.attention.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.4.attention.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.4.attention.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.4.intermediate.dense.weight, Shape: torch.Size([3072, 768])\n",
            "Parameter Name: encoder.layer.4.intermediate.dense.bias, Shape: torch.Size([3072])\n",
            "Parameter Name: encoder.layer.4.output.dense.weight, Shape: torch.Size([768, 3072])\n",
            "Parameter Name: encoder.layer.4.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.4.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.4.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.5.attention.self.query.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.5.attention.self.query.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.5.attention.self.key.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.5.attention.self.key.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.5.attention.self.value.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.5.attention.self.value.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.5.attention.output.dense.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.5.attention.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.5.attention.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.5.attention.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.5.intermediate.dense.weight, Shape: torch.Size([3072, 768])\n",
            "Parameter Name: encoder.layer.5.intermediate.dense.bias, Shape: torch.Size([3072])\n",
            "Parameter Name: encoder.layer.5.output.dense.weight, Shape: torch.Size([768, 3072])\n",
            "Parameter Name: encoder.layer.5.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.5.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.5.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.6.attention.self.query.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.6.attention.self.query.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.6.attention.self.key.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.6.attention.self.key.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.6.attention.self.value.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.6.attention.self.value.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.6.attention.output.dense.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.6.attention.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.6.attention.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.6.attention.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.6.intermediate.dense.weight, Shape: torch.Size([3072, 768])\n",
            "Parameter Name: encoder.layer.6.intermediate.dense.bias, Shape: torch.Size([3072])\n",
            "Parameter Name: encoder.layer.6.output.dense.weight, Shape: torch.Size([768, 3072])\n",
            "Parameter Name: encoder.layer.6.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.6.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.6.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.7.attention.self.query.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.7.attention.self.query.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.7.attention.self.key.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.7.attention.self.key.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.7.attention.self.value.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.7.attention.self.value.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.7.attention.output.dense.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.7.attention.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.7.attention.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.7.attention.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.7.intermediate.dense.weight, Shape: torch.Size([3072, 768])\n",
            "Parameter Name: encoder.layer.7.intermediate.dense.bias, Shape: torch.Size([3072])\n",
            "Parameter Name: encoder.layer.7.output.dense.weight, Shape: torch.Size([768, 3072])\n",
            "Parameter Name: encoder.layer.7.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.7.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.7.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.8.attention.self.query.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.8.attention.self.query.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.8.attention.self.key.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.8.attention.self.key.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.8.attention.self.value.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.8.attention.self.value.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.8.attention.output.dense.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.8.attention.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.8.attention.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.8.attention.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.8.intermediate.dense.weight, Shape: torch.Size([3072, 768])\n",
            "Parameter Name: encoder.layer.8.intermediate.dense.bias, Shape: torch.Size([3072])\n",
            "Parameter Name: encoder.layer.8.output.dense.weight, Shape: torch.Size([768, 3072])\n",
            "Parameter Name: encoder.layer.8.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.8.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.8.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.9.attention.self.query.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.9.attention.self.query.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.9.attention.self.key.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.9.attention.self.key.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.9.attention.self.value.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.9.attention.self.value.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.9.attention.output.dense.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.9.attention.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.9.attention.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.9.attention.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.9.intermediate.dense.weight, Shape: torch.Size([3072, 768])\n",
            "Parameter Name: encoder.layer.9.intermediate.dense.bias, Shape: torch.Size([3072])\n",
            "Parameter Name: encoder.layer.9.output.dense.weight, Shape: torch.Size([768, 3072])\n",
            "Parameter Name: encoder.layer.9.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.9.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.9.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.10.attention.self.query.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.10.attention.self.query.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.10.attention.self.key.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.10.attention.self.key.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.10.attention.self.value.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.10.attention.self.value.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.10.attention.output.dense.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.10.attention.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.10.attention.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.10.attention.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.10.intermediate.dense.weight, Shape: torch.Size([3072, 768])\n",
            "Parameter Name: encoder.layer.10.intermediate.dense.bias, Shape: torch.Size([3072])\n",
            "Parameter Name: encoder.layer.10.output.dense.weight, Shape: torch.Size([768, 3072])\n",
            "Parameter Name: encoder.layer.10.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.10.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.10.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.11.attention.self.query.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.11.attention.self.query.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.11.attention.self.key.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.11.attention.self.key.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.11.attention.self.value.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.11.attention.self.value.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.11.attention.output.dense.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: encoder.layer.11.attention.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.11.attention.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.11.attention.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.11.intermediate.dense.weight, Shape: torch.Size([3072, 768])\n",
            "Parameter Name: encoder.layer.11.intermediate.dense.bias, Shape: torch.Size([3072])\n",
            "Parameter Name: encoder.layer.11.output.dense.weight, Shape: torch.Size([768, 3072])\n",
            "Parameter Name: encoder.layer.11.output.dense.bias, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.11.output.LayerNorm.weight, Shape: torch.Size([768])\n",
            "Parameter Name: encoder.layer.11.output.LayerNorm.bias, Shape: torch.Size([768])\n",
            "Parameter Name: pooler.dense.weight, Shape: torch.Size([768, 768])\n",
            "Parameter Name: pooler.dense.bias, Shape: torch.Size([768])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "# 指定模型名称\n",
        "model_name = '/content/drive/MyDrive/bert-base-uncased/bert-base-uncased'\n",
        "\n",
        "# 读取模型对应的tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# 载入模型\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# 打印模型所有参数的名称和形状\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Parameter Name: {name}, Shape: {param.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3a2916afbbd3177",
      "metadata": {
        "id": "c3a2916afbbd3177"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fac13bc3ec5f6e38",
      "metadata": {
        "id": "fac13bc3ec5f6e38",
        "outputId": "fca14857-f18d-4332-b8ee-634cb1ea5265"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid character '，' (U+FF0C) (2054479218.py, line 6)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    在本章节中，你将基于上面的BERT代码和AG NEWS数据集进行基于预训练模型BERT的文本分类。你将完善下述代码同时探索多种句子聚合方式对结果的影响，其中句子聚合方式指的是从词嵌入中得到句子嵌入的过程。需要探索的句子聚合方式包括：\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '，' (U+FF0C)\n"
          ]
        }
      ],
      "source": [
        "### **3. 使用预训练模型进行文本分类**\n",
        "可能需要安装transformers包\n",
        "\n",
        "pip install transformers\n",
        "\n",
        "在本章节中，你将基于上面的BERT代码和AG NEWS数据集进行基于预训练模型BERT的文本分类。你将完善下述代码同时探索多种句子聚合方式对结果的影响，其中句子聚合方式指的是从词嵌入中得到句子嵌入的过程。需要探索的句子聚合方式包括：\n",
        "\n",
        "1. 直接使用[CLS]的嵌入表示当做句子嵌入。\n",
        "2. 使用mean-pooling平均一个句子中的所有词元得到嵌入\n",
        "3. 使用注意力机制给每个词元分配一个权重，通过加权求和的方式得到嵌入。你可以使用任意注意力机制计算。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0287de3d",
      "metadata": {
        "id": "0287de3d",
        "outputId": "867d8809-921b-40ab-9051-c1445b38fd56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "995be76f",
      "metadata": {
        "id": "995be76f",
        "outputId": "70778c51-6595-454a-d40b-d86f5c9e3a75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87ebfb827793b56f",
      "metadata": {
        "id": "87ebfb827793b56f"
      },
      "source": [
        "代码部分："
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VEE1lGnAYQt8",
        "outputId": "552e3b33-1788-481c-fd52-6709df4b0b29"
      },
      "id": "VEE1lGnAYQt8",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              },
              "id": "b3942ddd81a24ac6b97870d5a47f1bde"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModel\n",
        "\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-YjhzJTC5Xy",
        "outputId": "92534a5b-7978-4948-c7c4-86fcf18f4bf6"
      },
      "id": "S-YjhzJTC5Xy",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a4457ccdc5f9c56",
      "metadata": {
        "id": "9a4457ccdc5f9c56",
        "outputId": "f1184104-1d49-4341-a84d-f3b83ee96192",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 282/282 [04:48<00:00,  1.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.3169\n",
            "Test Accuracy: 0.9217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 282/282 [04:47<00:00,  1.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 0.1687\n",
            "Test Accuracy: 0.9246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 282/282 [04:48<00:00,  1.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 0.1171\n",
            "Test Accuracy: 0.9221\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# **1. 加载 AG NEWS 数据集**\n",
        "df = pd.read_csv(\"./drive/MyDrive/ag/train.csv\")  # 请替换成你的文件路径\n",
        "df.columns = [\"label\", \"title\", \"description\"]  # CSV 有3列: 标签, 标题, 描述\n",
        "df[\"text\"] = df[\"title\"] + \" \" + df[\"description\"]  # 合并标题和描述作为输入文本\n",
        "df[\"label\"] = df[\"label\"] - 1  # AG NEWS 的标签是 1-4，我们转换成 0-3\n",
        "train_texts, train_labels = df[\"text\"].tolist(), df[\"label\"].tolist()\n",
        "number = int(0.3 * len(train_texts))\n",
        "train_texts, train_labels = train_texts[: number], train_labels[: number]\n",
        "\n",
        "df = pd.read_csv(\"./drive/MyDrive/ag/test.csv\")  # 请替换成你的文件路径\n",
        "df.columns = [\"label\", \"title\", \"description\"]  # CSV 有3列: 标签, 标题, 描述\n",
        "df[\"text\"] = df[\"title\"] + \" \" + df[\"description\"]  # 合并标题和描述作为输入文本\n",
        "df[\"label\"] = df[\"label\"] - 1  # AG NEWS 的标签是 1-4，我们转换成 0-3\n",
        "test_texts, test_labels = df[\"text\"].tolist(), df[\"label\"].tolist()\n",
        "\n",
        "# **2. 加载 BERT Tokenizer**\n",
        "model_name = \"./drive/MyDrive/bert-base-uncased/bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# **3. 处理数据**\n",
        "class AGNewsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=50):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text, truncation=True, padding=\"max_length\", max_length=self.max_length, return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
        "        } # 此处会自动生成BERT输入所需要的attention_mask\n",
        "\n",
        "\n",
        "train_dataset = AGNewsDataset(train_texts, train_labels, tokenizer)\n",
        "test_dataset = AGNewsDataset(test_texts, test_labels, tokenizer)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# **4. 定义和加载BERT分类模型**\n",
        "#TODO:定义模型并且放到GPU上\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "model = model.to(device)\n",
        "\n",
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self, model_name, num_labels):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = torch.nn.Linear(self.bert.config.hidden_size,num_labels)\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        logits = self.bert(input_ids = input_ids, attention_mask = attention_mask)\n",
        "        logits = logits.last_hidden_state[:,0,:]\n",
        "        logits = self.dropout(logits)\n",
        "        logits = self.classifier(logits)\n",
        "        return logits\n",
        "\n",
        "model = BERTClassifier(model_name, num_labels=4).to(device)\n",
        "\n",
        "\n",
        "# **5. 设置优化器和损失函数**\n",
        "#TODO: 定义优化器和损失函数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
        "# **6. 训练 BERT**\n",
        "EPOCHS = 3\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    loop = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\")\n",
        "\n",
        "    for batch in loop:\n",
        "        #TODO: 基于后面需要打印的损失，定义训练过程\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "        output = model(input_ids, attention_mask)\n",
        "        loss = criterion(output, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss+=loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_dataloader):.4f}\")\n",
        "\n",
        "    # **7. 评估模型**\n",
        "    model.eval()\n",
        "    preds, true_labels = [], []\n",
        "    with torch.no_grad():\n",
        "      for batch in test_dataloader:\n",
        "        inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = model(**inputs)\n",
        "        preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(true_labels, preds)\n",
        "    print(f\"Test Accuracy: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7f940fb28765a01",
      "metadata": {
        "id": "f7f940fb28765a01"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7181ba5e93a8336a",
      "metadata": {
        "id": "7181ba5e93a8336a"
      },
      "outputs": [],
      "source": [
        "训练笔记：你如果觉得训练速度慢，可以尝试增大batch size，不过注意不要炸显存。\n",
        "\n",
        "根据实验数据，三种句子聚合方式的最终测试准确率如下：\n",
        "\n",
        "思考题1：你觉得以上三种得到句子嵌入的方案，哪种效果会最好，哪种效果会最差？为什么？\n",
        "\n",
        "思考题2：如果一个文档包括多个句子，我们需要获得其中每个句子的嵌入表示。那么，我们应该怎么利用BERT得到每个句子的嵌入？"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91deae1f06ccff3b",
      "metadata": {
        "id": "91deae1f06ccff3b"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "df = pd.read_csv(\"./drive/MyDrive/ag/train.csv\")\n",
        "df.columns = [\"label\", \"title\", \"description\"]\n",
        "df[\"text\"] = df[\"title\"] + \" \" + df[\"description\"]\n",
        "df[\"label\"] = df[\"label\"] - 1\n",
        "train_texts, train_labels = df[\"text\"].tolist(), df[\"label\"].tolist()\n",
        "number = int(0.3 * len(train_texts))\n",
        "train_texts, train_labels = train_texts[:number], train_labels[:number]\n",
        "\n",
        "df = pd.read_csv(\"./drive/MyDrive/ag/test.csv\")\n",
        "df.columns = [\"label\", \"title\", \"description\"]\n",
        "df[\"text\"] = df[\"title\"] + \" \" + df[\"description\"]\n",
        "df[\"label\"] = df[\"label\"] - 1\n",
        "test_texts, test_labels = df[\"text\"].tolist(), df[\"label\"].tolist()\n",
        "\n",
        "model_name = \"./drive/MyDrive/bert-base-uncased/bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "class AGNewsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=50):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text, truncation=True, padding=\"max_length\",\n",
        "            max_length=self.max_length, return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "train_dataset = AGNewsDataset(train_texts, train_labels, tokenizer)\n",
        "test_dataset = AGNewsDataset(test_texts, test_labels, tokenizer)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self, model_name, num_labels, pool_type='cls'):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "        self.pool_type = pool_type\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "        if pool_type == 'attention':\n",
        "            self.attention = nn.Sequential(\n",
        "                nn.Linear(self.bert.config.hidden_size, 128),\n",
        "                nn.Tanh(),\n",
        "                nn.Linear(128, 1)\n",
        "            )\n",
        "\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                           attention_mask=attention_mask)\n",
        "        last_hidden = outputs.last_hidden_state  # [batch, seq_len, hidden_size]\n",
        "\n",
        "        # CLS pooling (直接使用[CLS] token)\n",
        "        if self.pool_type == 'cls':\n",
        "            pooled = last_hidden[:, 0, :]\n",
        "\n",
        "        # Mean pooling (平均所有token)\n",
        "        elif self.pool_type == 'mean':\n",
        "            mask = attention_mask.unsqueeze(-1).expand(last_hidden.size()).float()\n",
        "            sum_hidden = torch.sum(last_hidden * mask, 1)\n",
        "            sum_mask = torch.clamp(mask.sum(1), min=1e-9)\n",
        "            pooled = sum_hidden / sum_mask\n",
        "\n",
        "        # Attention pooling (加权平均)\n",
        "        elif self.pool_type == 'attention':\n",
        "            attn_weights = self.attention(last_hidden).squeeze(-1)  # [batch, seq_len]\n",
        "            attn_weights = attn_weights.masked_fill(attention_mask == 0, float('-inf'))\n",
        "            attn_weights = torch.softmax(attn_weights, dim=1)\n",
        "            pooled = torch.sum(last_hidden * attn_weights.unsqueeze(-1), dim=1)\n",
        "\n",
        "        pooled = self.dropout(pooled)\n",
        "        return self.classifier(pooled)\n",
        "\n",
        "def train_and_evaluate(pool_type):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = BERTClassifier(model_name, num_labels=4, pool_type=pool_type).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "    EPOCHS = 3\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        loop = tqdm(train_dataloader, desc=f\"Epoch {epoch+1} [{pool_type}]\")\n",
        "\n",
        "        for batch in loop:\n",
        "            optimizer.zero_grad()\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_dataloader):.4f}\")\n",
        "\n",
        "        model.eval()\n",
        "        preds, true_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for batch in test_dataloader:\n",
        "                input_ids = batch[\"input_ids\"].to(device)\n",
        "                attention_mask = batch[\"attention_mask\"].to(device)\n",
        "                labels = batch[\"labels\"].cpu().numpy()\n",
        "\n",
        "                outputs = model(input_ids, attention_mask)\n",
        "                preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
        "                true_labels.extend(labels)\n",
        "\n",
        "        acc = accuracy_score(true_labels, preds)\n",
        "        print(f\"Test Accuracy ({pool_type}): {acc:.4f}\\n\")\n",
        "\n",
        "    return acc\n",
        "\n",
        "results = {}\n",
        "for pool_type in ['cls', 'mean', 'attention']:\n",
        "    print(f\"\\n=== Evaluating {pool_type} pooling ===\")\n",
        "    results[pool_type] = train_and_evaluate(pool_type)\n",
        "\n",
        "print(\"\\n=== Final Results ===\")\n",
        "for k, v in results.items():\n",
        "    print(f\"{k} pooling accuracy: {v:.4f}\")"
      ],
      "metadata": {
        "id": "_uENspCeOmIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bf07c84-cd18-4e25-cd22-c6807f3d40cf"
      },
      "id": "_uENspCeOmIx",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Evaluating cls pooling ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [cls]: 100%|██████████| 282/282 [04:38<00:00,  1.01it/s, loss=0.389]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.3219\n",
            "Test Accuracy (cls): 0.9149\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [cls]: 100%|██████████| 282/282 [04:38<00:00,  1.01it/s, loss=0.313]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 0.1707\n",
            "Test Accuracy (cls): 0.9221\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [cls]: 100%|██████████| 282/282 [04:38<00:00,  1.01it/s, loss=0.219]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 0.1193\n",
            "Test Accuracy (cls): 0.9226\n",
            "\n",
            "\n",
            "=== Evaluating mean pooling ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [mean]: 100%|██████████| 282/282 [04:40<00:00,  1.01it/s, loss=0.356]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.3290\n",
            "Test Accuracy (mean): 0.9180\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [mean]: 100%|██████████| 282/282 [04:41<00:00,  1.00it/s, loss=0.408]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 0.1773\n",
            "Test Accuracy (mean): 0.9203\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [mean]: 100%|██████████| 282/282 [04:40<00:00,  1.01it/s, loss=0.236]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 0.1239\n",
            "Test Accuracy (mean): 0.9236\n",
            "\n",
            "\n",
            "=== Evaluating attention pooling ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [attention]: 100%|██████████| 282/282 [04:41<00:00,  1.00it/s, loss=0.0723]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.3276\n",
            "Test Accuracy (attention): 0.9186\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [attention]: 100%|██████████| 282/282 [04:41<00:00,  1.00it/s, loss=0.0607]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 0.1694\n",
            "Test Accuracy (attention): 0.9243\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [attention]: 100%|██████████| 282/282 [04:41<00:00,  1.00it/s, loss=0.132]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 0.1181\n",
            "Test Accuracy (attention): 0.9137\n",
            "\n",
            "\n",
            "=== Final Results ===\n",
            "cls pooling accuracy: 0.9226\n",
            "mean pooling accuracy: 0.9236\n",
            "attention pooling accuracy: 0.9137\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}