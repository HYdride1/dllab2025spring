{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMNkUejzNFrQ"
      },
      "source": [
        "<a name=\"top\"></a>\n",
        "# **深度学习实验课之 Meta Learning: Few-shot Classification**\n",
        "\n",
        "This is the sample code.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdpzIMG6XsGK"
      },
      "source": [
        "## **Step 0: Check GPU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zjjHsZbaL7SV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Apr 11 06:01:34 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.120                Driver Version: 550.120        CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 3070        Off |   00000000:01:00.0 Off |                  N/A |\n",
            "| 33%   37C    P8             14W /  220W |     785MiB /   8192MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A      1529      G   ...dd60467559eb0d1e229c6452cf8447/node          4MiB |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ3wvyjnXwGX"
      },
      "source": [
        "## **Step 1: Download Data**\n",
        "\n",
        "Run the cell to download data, which has been pre-processed.  \n",
        "The training/validation dataset has been augmented, so extra data augmentation is not required.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g7Gt4Jucug41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-04-11 06:04:48--  https://box.nju.edu.cn/f/06579572abb542249517/?dl=1\n",
            "Resolving box.nju.edu.cn (box.nju.edu.cn)... 210.28.130.6\n",
            "Connecting to box.nju.edu.cn (box.nju.edu.cn)|210.28.130.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://box.nju.edu.cn/seafhttp/files/e6790a61-7bbd-439d-948b-19aeaf8d58f3/Omniglot.tar.gz [following]\n",
            "--2025-04-11 06:04:48--  https://box.nju.edu.cn/seafhttp/files/e6790a61-7bbd-439d-948b-19aeaf8d58f3/Omniglot.tar.gz\n",
            "Reusing existing connection to box.nju.edu.cn:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5718170 (5.5M) [application/octet-stream]\n",
            "Saving to: ‘./Omniglot.tar.gz’\n",
            "\n",
            "./Omniglot.tar.gz   100%[===================>]   5.45M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-04-11 06:04:48 (67.7 MB/s) - ‘./Omniglot.tar.gz’ saved [5718170/5718170]\n",
            "\n",
            "--2025-04-11 06:04:48--  https://box.nju.edu.cn/f/9508a9c341344d6e9164/?dl=1\n",
            "Resolving box.nju.edu.cn (box.nju.edu.cn)... 210.28.130.6\n",
            "Connecting to box.nju.edu.cn (box.nju.edu.cn)|210.28.130.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://box.nju.edu.cn/seafhttp/files/2d4cd0a0-712e-446a-9df6-012fad272b70/Omniglot-test.tar.gz [following]\n",
            "--2025-04-11 06:04:48--  https://box.nju.edu.cn/seafhttp/files/2d4cd0a0-712e-446a-9df6-012fad272b70/Omniglot-test.tar.gz\n",
            "Reusing existing connection to box.nju.edu.cn:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 652993 (638K) [application/octet-stream]\n",
            "Saving to: ‘./Omniglot-test.tar.gz’\n",
            "\n",
            "./Omniglot-test.tar 100%[===================>] 637.69K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-04-11 06:04:49 (18.9 MB/s) - ‘./Omniglot-test.tar.gz’ saved [652993/652993]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "workspace_dir = '.'\n",
        "\n",
        "# Download dataset\n",
        "!wget https://box.nju.edu.cn/f/06579572abb542249517/?dl=1 \\\n",
        "    -O \"{workspace_dir}/Omniglot.tar.gz\"\n",
        "!wget https://box.nju.edu.cn/f/9508a9c341344d6e9164/?dl=1 \\\n",
        "    -O \"{workspace_dir}/Omniglot-test.tar.gz\"\n",
        "\n",
        "# Use `tar' command to decompress\n",
        "!tar -zxf \"{workspace_dir}/Omniglot.tar.gz\" -C \"{workspace_dir}/\"\n",
        "!tar -zxf \"{workspace_dir}/Omniglot-test.tar.gz\" -C \"{workspace_dir}/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baVsWfcSYHVN"
      },
      "source": [
        "## **Step 2: Build the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqiOdDLgYOlQ"
      },
      "source": [
        "### Library importation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-9pfkqh8gxHD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEVICE = cuda\n"
          ]
        }
      ],
      "source": [
        "# Import modules we need\n",
        "import glob, random\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "# Check device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"DEVICE = {device}\")\n",
        "\n",
        "# Fix random seeds\n",
        "random_seed = 0\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(random_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TlwLtC1YRT7"
      },
      "source": [
        "### Model Construction Preliminaries\n",
        "\n",
        "Since our task is image classification, we need to build a CNN-based model.  \n",
        "However, to implement MAML algorithm, we should adjust some code in `nn.Module`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFwB3tuEDYfy"
      },
      "source": [
        "Take a look at MAML pseudocode...\n",
        "\n",
        "<img src=\"https://i.imgur.com/9aHlvfX.png\" width=\"50%\" />\n",
        "\n",
        "On the 10-th line, what we take gradients on are those $\\theta$ representing  \n",
        "<font color=\"#0CC\">**the original model parameters**</font> (outer loop) instead of those in  the  \n",
        "<font color=\"#0C0\">**inner loop**</font>, so we need to use `functional_forward` to compute the output  \n",
        "logits of input image instead of `forward` in `nn.Module`.\n",
        "\n",
        "The following defines these functions.\n",
        "\n",
        "<!-- 由於在第10行，我們是要對原本的參數 θ 微分，並非 inner-loop (Line5~8) 的 θ' 微分，因此在 inner-loop，我們需要用 functional forward 的方式算出 input image 的 output logits，而不是直接用 nn.module 裡面的 forward（直接對 θ 微分）。在下面我們分別定義了 functional forward 以及 forward 函數。 -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuYQiPeQYc__"
      },
      "source": [
        "### Model block definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GgFbbKHYg3Hk"
      },
      "outputs": [],
      "source": [
        "def ConvBlock(in_ch: int, out_ch: int):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "        nn.BatchNorm2d(out_ch),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    )\n",
        "\n",
        "\n",
        "def ConvBlockFunction(x, w, b, w_bn, b_bn):\n",
        "    x = F.conv2d(x, w, b, padding=1)\n",
        "    x = F.batch_norm(\n",
        "        x, running_mean=None, running_var=None, weight=w_bn, bias=b_bn, training=True\n",
        "    )\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQEzgWN7fi7B"
      },
      "source": [
        "### Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0bFBGEQoHQUW"
      },
      "outputs": [],
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, in_ch, k_way):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.conv1 = ConvBlock(in_ch, 64)\n",
        "        self.conv2 = ConvBlock(64, 64)\n",
        "        self.conv3 = ConvBlock(64, 64)\n",
        "        self.conv4 = ConvBlock(64, 64)\n",
        "        self.logits = nn.Linear(64, k_way)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.logits(x)\n",
        "        return x\n",
        "\n",
        "    def functional_forward(self, x, params):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "        x: input images [batch, 1, 28, 28]\n",
        "        params: model parameters,\n",
        "                i.e. weights and biases of convolution\n",
        "                     and weights and biases of\n",
        "                                   batch normalization\n",
        "                type is an OrderedDict\n",
        "\n",
        "        Arguments:\n",
        "        x: input images [batch, 1, 28, 28]\n",
        "        params: The model parameters,\n",
        "                i.e. weights and biases of convolution\n",
        "                     and batch normalization layers\n",
        "                It's an `OrderedDict`\n",
        "        \"\"\"\n",
        "        for block in [1, 2, 3, 4]:\n",
        "            x = ConvBlockFunction(\n",
        "                x,\n",
        "                params[f\"conv{block}.0.weight\"],\n",
        "                params[f\"conv{block}.0.bias\"],\n",
        "                params.get(f\"conv{block}.1.weight\"),\n",
        "                params.get(f\"conv{block}.1.bias\"),\n",
        "            )\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.linear(x, params[\"logits.weight\"], params[\"logits.bias\"])\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmJq_0B9Yj0G"
      },
      "source": [
        "### Create Label\n",
        "\n",
        "This function is used to create labels.  \n",
        "In a N-way K-shot few-shot classification problem,\n",
        "each task has `n_way` classes, while there are `k_shot` images for each class.  \n",
        "This is a function that creates such labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQF5vgLvg5aX",
        "outputId": "25658cf3-4604-452c-f590-6626be9d7a07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 0, 1, 1, 2, 2, 3, 3, 4, 4])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def create_label(n_way, k_shot):\n",
        "    return torch.arange(n_way).repeat_interleave(k_shot).long()\n",
        "\n",
        "\n",
        "# Try to create labels for 5-way 2-shot setting\n",
        "create_label(5, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nCFv9PGw50J"
      },
      "source": [
        "### Accuracy calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FahDr0xQw50S"
      },
      "outputs": [],
      "source": [
        "def calculate_accuracy(logits, labels):\n",
        "    \"\"\"utility function for accuracy calculation\"\"\"\n",
        "    acc = np.asarray(\n",
        "        [(torch.argmax(logits, -1).cpu().numpy() == labels.cpu().numpy())]\n",
        "    ).mean()\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hl7ro2mYzsI"
      },
      "source": [
        "### Define Dataset\n",
        "\n",
        "Define the dataset.  \n",
        "The dataset returns images of a random character, with (`k_shot + q_query`) images,  \n",
        "so the size of returned tensor is `[k_shot+q_query, 1, 28, 28]`.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-tJ2mot9hHPb"
      },
      "outputs": [],
      "source": [
        "# Dataset for train and val\n",
        "class Omniglot(Dataset):\n",
        "    def __init__(self, data_dir, k_shot, q_query, task_num=None):\n",
        "        self.file_list = [\n",
        "            f for f in glob.glob(data_dir + \"**/character*\", recursive=True)\n",
        "        ]\n",
        "        # limit task number if task_num is set\n",
        "        if task_num is not None:\n",
        "            self.file_list = self.file_list[: min(len(self.file_list), task_num)]\n",
        "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
        "        self.n = k_shot + q_query\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # For random sampling the characters we want.\n",
        "        img_path = self.file_list[idx]\n",
        "        img_list = [f for f in glob.glob(img_path + \"**/*.png\", recursive=True)]\n",
        "        img_list.sort()\n",
        "\n",
        "        sample = np.arange(len(img_list))\n",
        "        np.random.shuffle(sample)\n",
        "\n",
        "        # `k_shot + q_query` examples for each character\n",
        "        imgs = [self.transform(Image.open(img_list[idx])) for idx in sample[:self.n]]\n",
        "        imgs = torch.stack(imgs)\n",
        "        return imgs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRzjBWhwI6tc"
      },
      "source": [
        "## **Step 3: Learning Algorithms**\n",
        "\n",
        "### Transfer learning\n",
        "\n",
        "The solver first chose five task from the training set, then do normal classification training on the chosen five tasks. In inference, the model finetune for `inner_train_step` steps on the support set images, and than do inference on the query set images.\n",
        "\n",
        "For consistant with the meta-learning solver, the base solver has the exactly same input and output format with the meta-learning solver.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "R_jGPJHK7KpC"
      },
      "outputs": [],
      "source": [
        "def BaseSolver(\n",
        "    model,\n",
        "    optimizer,\n",
        "    x,\n",
        "    n_way,\n",
        "    k_shot,\n",
        "    q_query,\n",
        "    loss_fn,\n",
        "    inner_train_step=1,\n",
        "    inner_lr=0.4,\n",
        "    train=True,\n",
        "    return_labels=False,\n",
        "):\n",
        "    criterion, task_loss, task_acc = loss_fn, [], []\n",
        "    labels = []\n",
        "\n",
        "    for meta_batch in x:\n",
        "        # Get data\n",
        "        support_set = meta_batch[: n_way * k_shot]\n",
        "        query_set = meta_batch[n_way * k_shot :]\n",
        "\n",
        "        if train:\n",
        "            \"\"\" training loop \"\"\"\n",
        "            # Use the support set to calculate loss\n",
        "            labels = create_label(n_way, k_shot).to(device)\n",
        "            logits = model.forward(support_set)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            task_loss.append(loss)\n",
        "            task_acc.append(calculate_accuracy(logits, labels))\n",
        "        else:\n",
        "            \"\"\" validation / testing loop \"\"\"\n",
        "            # First update model with support set images for `inner_train_step` steps\n",
        "            fast_weights = OrderedDict(model.named_parameters())\n",
        "\n",
        "\n",
        "            for inner_step in range(inner_train_step):\n",
        "                # Simply training\n",
        "                train_label = create_label(n_way, k_shot).to(device)\n",
        "                logits = model.functional_forward(support_set, fast_weights)\n",
        "                loss = criterion(logits, train_label)\n",
        "\n",
        "                grads = torch.autograd.grad(loss, fast_weights.values(), create_graph=True)\n",
        "                # Perform SGD\n",
        "                fast_weights = OrderedDict(\n",
        "                    (name, param - inner_lr * grad)\n",
        "                    for ((name, param), grad) in zip(fast_weights.items(), grads)\n",
        "                )\n",
        "\n",
        "            if not return_labels:\n",
        "                \"\"\" validation \"\"\"\n",
        "                val_label = create_label(n_way, q_query).to(device)\n",
        "\n",
        "                logits = model.functional_forward(query_set, fast_weights)\n",
        "                loss = criterion(logits, val_label)\n",
        "                task_loss.append(loss)\n",
        "                task_acc.append(calculate_accuracy(logits, val_label))\n",
        "            else:\n",
        "                \"\"\" testing \"\"\"\n",
        "                logits = model.functional_forward(query_set, fast_weights)\n",
        "                labels.extend(torch.argmax(logits, -1).cpu().numpy())\n",
        "\n",
        "    if return_labels:\n",
        "        return labels\n",
        "\n",
        "    batch_loss = torch.stack(task_loss).mean()\n",
        "    task_acc = np.mean(task_acc)\n",
        "\n",
        "    if train:\n",
        "        # Update model\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return batch_loss, task_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm5iVp90Ylii"
      },
      "source": [
        "### Meta Learning\n",
        "\n",
        "Here is the main Meta Learning algorithm.\n",
        "\n",
        "Please finish the TODO blocks for the inner and outer loop update rules.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KjNxrWW_yNck"
      },
      "outputs": [],
      "source": [
        "def MetaSolver(\n",
        "    model,\n",
        "    optimizer,\n",
        "    x,\n",
        "    n_way,\n",
        "    k_shot,\n",
        "    q_query,\n",
        "    loss_fn,\n",
        "    inner_train_step=1,\n",
        "    inner_lr=0.4,\n",
        "    train=True,\n",
        "    return_labels=False\n",
        "):\n",
        "    criterion, task_loss, task_acc = loss_fn, [], []\n",
        "    labels = []\n",
        "\n",
        "    for meta_batch in x:\n",
        "        # Get data\n",
        "        support_set = meta_batch[: n_way * k_shot]\n",
        "        query_set = meta_batch[n_way * k_shot :]\n",
        "\n",
        "        # Copy the params for inner loop\n",
        "        fast_weights = OrderedDict(model.named_parameters())\n",
        "\n",
        "        ### ---------- INNER TRAIN LOOP ---------- ###\n",
        "        for inner_step in range(inner_train_step):\n",
        "            # Simply training\n",
        "            train_label = create_label(n_way, k_shot).to(device)\n",
        "            logits = model.functional_forward(support_set, fast_weights)\n",
        "            loss = criterion(logits, train_label)\n",
        "            # Inner gradients update! vvvvvvvvvvvvvvvvvvvv #\n",
        "            \"\"\" Inner Loop Update \"\"\"\n",
        "            # TODO: Finish the inner loop update rule\n",
        "            grads = torch.autograd.grad(loss, fast_weights.values(), create_graph=True)\n",
        "            fast_weights = OrderedDict(\n",
        "                    (name, param - inner_lr * grad)\n",
        "                    for ((name, param), grad) in zip(fast_weights.items(), grads)\n",
        "                )\n",
        "            # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ #\n",
        "\n",
        "        ### ---------- INNER VALID LOOP ---------- ###\n",
        "        if not return_labels:\n",
        "            \"\"\" training / validation \"\"\"\n",
        "            val_label = create_label(n_way, q_query).to(device)\n",
        "\n",
        "            # Collect gradients for outer loop\n",
        "            logits = model.functional_forward(query_set, fast_weights)\n",
        "            loss = criterion(logits, val_label)\n",
        "            task_loss.append(loss)\n",
        "            task_acc.append(calculate_accuracy(logits, val_label))\n",
        "        else:\n",
        "            \"\"\" testing \"\"\"\n",
        "            logits = model.functional_forward(query_set, fast_weights)\n",
        "            labels.extend(torch.argmax(logits, -1).cpu().numpy())\n",
        "\n",
        "    if return_labels:\n",
        "        return labels\n",
        "\n",
        "    # Update outer loop\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    meta_batch_loss = torch.stack(task_loss).mean()\n",
        "    if train:\n",
        "        \"\"\" Outer Loop Update \"\"\"\n",
        "        # TODO: Finish the outer loop update\n",
        "        meta_batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    task_acc = np.mean(task_acc)\n",
        "    return meta_batch_loss, task_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBoRBhVlZAST"
      },
      "source": [
        "## **Step 4: Initialization**\n",
        "\n",
        "After defining all components we need, the following initialize a model before training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip-i7aseftUF"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wFHmVcBhE4M"
      },
      "outputs": [],
      "source": [
        "n_way = 5\n",
        "k_shot = 1\n",
        "q_query = 1\n",
        "train_inner_train_step = 1\n",
        "val_inner_train_step =3\n",
        "inner_lr = 0.4\n",
        "meta_lr = 0.001\n",
        "meta_batch_size = 32\n",
        "max_epoch = 30\n",
        "eval_batches = 20\n",
        "train_data_path = \"./Omniglot/images_background/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvzo7NVpfu5V"
      },
      "source": [
        "### Dataloader initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "3I13GJavhP0_"
      },
      "outputs": [],
      "source": [
        "def dataloader_init(datasets, shuffle=True, num_workers=2):\n",
        "    train_set, val_set = datasets\n",
        "    train_loader = DataLoader(\n",
        "        train_set,\n",
        "        # The \"batch_size\" here is not \\\n",
        "        #    the meta batch size, but  \\\n",
        "        #    how many different        \\\n",
        "        #    characters in a task,     \\\n",
        "        #    i.e. the \"n_way\" in       \\\n",
        "        #    few-shot classification.\n",
        "        batch_size=n_way,\n",
        "        num_workers=num_workers,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_set, batch_size=n_way, num_workers=num_workers, shuffle=shuffle, drop_last=True\n",
        "    )\n",
        "\n",
        "    train_iter = iter(train_loader)\n",
        "    val_iter = iter(val_loader)\n",
        "    return (train_loader, val_loader), (train_iter, val_iter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVund--bfw0e"
      },
      "source": [
        "### Model & optimizer initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "Kxug882ihF2B"
      },
      "outputs": [],
      "source": [
        "def model_init():\n",
        "    meta_model = Classifier(1, n_way).to(device)\n",
        "    optimizer = torch.optim.Adam(meta_model.parameters(), lr=meta_lr)\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    return meta_model, optimizer, loss_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj8cLRNLf2zg"
      },
      "source": [
        "### Utility function to get a meta-batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "zrkCSsxOhC-N"
      },
      "outputs": [],
      "source": [
        "def get_meta_batch(meta_batch_size, k_shot, q_query, data_loader, iterator):\n",
        "    data = []\n",
        "    for _ in range(meta_batch_size):\n",
        "        try:\n",
        "            # a \"task_data\" tensor is representing \\\n",
        "            #     the data of a task, with size of \\\n",
        "            #     [n_way, k_shot+q_query, 1, 28, 28]\n",
        "            task_data = next(iterator)\n",
        "        except StopIteration:\n",
        "            iterator = iter(data_loader)\n",
        "            task_data = next(iterator)\n",
        "        train_data = task_data[:, :k_shot].reshape(-1, 1, 28, 28)\n",
        "        val_data = task_data[:, k_shot:].reshape(-1, 1, 28, 28)\n",
        "        task_data = torch.cat((train_data, val_data), 0)\n",
        "        data.append(task_data)\n",
        "    return torch.stack(data).to(device), iterator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWQczA3FwjEG"
      },
      "source": [
        "<a name=\"mainprog\" id=\"mainprog\"></a>\n",
        "## **Step 5: Main program for training & testing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EirEnaof7ep"
      },
      "source": [
        "### Start training!\n",
        "With `solver = 'base'`, the solver is a transfer learning algorithm.\n",
        "\n",
        "Once you finish the TODO blocks in the `MetaSolver`, change the variable `solver = 'meta'` to start training with meta learning algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "JQZjJrLAhBWw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  3.828\t  Accuracy:  23.438 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  8.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  35.000 %\n",
            "Epoch 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  1.940\t  Accuracy:  27.187 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  36.000 %\n",
            "Epoch 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  1.520\t  Accuracy:  34.844 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  8.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  37.000 %\n",
            "Epoch 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  1.421\t  Accuracy:  40.625 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  44.000 %\n",
            "Epoch 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  1.326\t  Accuracy:  43.750 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  8.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  41.000 %\n",
            "Epoch 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  1.248\t  Accuracy:  52.500 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  45.000 %\n",
            "Epoch 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  1.260\t  Accuracy:  48.594 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  7.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  42.000 %\n",
            "Epoch 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  1.257\t  Accuracy:  50.313 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  49.000 %\n",
            "Epoch 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  1.259\t  Accuracy:  49.688 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  8.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  44.000 %\n",
            "Epoch 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  1.210\t  Accuracy:  51.875 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  45.000 %\n",
            "Epoch 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  1.194\t  Accuracy:  55.625 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  7.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  43.000 %\n",
            "Epoch 12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  1.207\t  Accuracy:  54.062 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  44.000 %\n",
            "Epoch 13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  1.173\t  Accuracy:  55.937 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  7.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  49.000 %\n",
            "Epoch 14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  1.166\t  Accuracy:  57.656 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  42.000 %\n",
            "Epoch 15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  1.119\t  Accuracy:  58.438 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  8.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  49.000 %\n",
            "Epoch 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  1.111\t  Accuracy:  59.219 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  49.000 %\n",
            "Epoch 17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  1.103\t  Accuracy:  57.969 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  8.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  42.000 %\n",
            "Epoch 18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  1.076\t  Accuracy:  63.750 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  47.000 %\n",
            "Epoch 19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  1.075\t  Accuracy:  61.875 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  6.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  50.000 %\n",
            "Epoch 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  1.026\t  Accuracy:  64.219 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  50.000 %\n",
            "Epoch 21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  1.054\t  Accuracy:  62.031 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  50.000 %\n",
            "Epoch 22\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  1.036\t  Accuracy:  59.375 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  7.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  54.000 %\n",
            "Epoch 23\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.968\t  Accuracy:  65.938 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  58.000 %\n",
            "Epoch 24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.995\t  Accuracy:  64.844 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  54.000 %\n",
            "Epoch 25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.927\t  Accuracy:  67.188 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  60.000 %\n",
            "Epoch 26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.933\t  Accuracy:  66.875 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  5.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  54.000 %\n",
            "Epoch 27\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.929\t  Accuracy:  67.344 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  52.000 %\n",
            "Epoch 28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.898\t  Accuracy:  68.125 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  8.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  56.000 %\n",
            "Epoch 29\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.909\t  Accuracy:  67.500 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  63.000 %\n",
            "Epoch 30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.826\t  Accuracy:  72.188 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  7.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  60.000 %\n",
            "Epoch 31\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.844\t  Accuracy:  71.875 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  61.000 %\n",
            "Epoch 32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.833\t  Accuracy:  71.094 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  8.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  51.000 %\n",
            "Epoch 33\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.793\t  Accuracy:  75.156 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  59.000 %\n",
            "Epoch 34\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.768\t  Accuracy:  73.906 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  8.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  65.000 %\n",
            "Epoch 35\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  2.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.741\t  Accuracy:  75.000 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  62.000 %\n",
            "Epoch 36\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.752\t  Accuracy:  72.656 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  8.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  72.000 %\n",
            "Epoch 37\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.709\t  Accuracy:  75.000 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  71.000 %\n",
            "Epoch 38\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.723\t  Accuracy:  75.937 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  8.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  75.000 %\n",
            "Epoch 39\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.682\t  Accuracy:  77.188 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  59.000 %\n",
            "Epoch 40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.672\t  Accuracy:  77.188 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  75.000 %\n",
            "Epoch 41\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.638\t  Accuracy:  77.812 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  8.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  63.000 %\n",
            "Epoch 42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.643\t  Accuracy:  80.156 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  77.000 %\n",
            "Epoch 43\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  2.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.631\t  Accuracy:  80.781 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  8.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  75.000 %\n",
            "Epoch 44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.614\t  Accuracy:  79.687 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  77.000 %\n",
            "Epoch 45\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.566\t  Accuracy:  83.281 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  7.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  67.000 %\n",
            "Epoch 46\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.575\t  Accuracy:  82.187 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  79.000 %\n",
            "Epoch 47\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.542\t  Accuracy:  82.344 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  8.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  76.000 %\n",
            "Epoch 48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.506\t  Accuracy:  83.281 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  81.000 %\n",
            "Epoch 49\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.544\t  Accuracy:  82.187 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  8.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  72.000 %\n",
            "Epoch 50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loss    :  0.505\t  Accuracy:  84.688 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Validation accuracy:  74.000 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "solver = 'meta' # base, meta\n",
        "meta_model, optimizer, loss_fn = model_init()\n",
        "\n",
        "# init solver and dataset according to solver type\n",
        "if solver == 'base':\n",
        "    max_epoch = 5 # the base solver only needs 5 epochs\n",
        "    Solver = BaseSolver\n",
        "    train_set, val_set = torch.utils.data.random_split(\n",
        "        Omniglot(train_data_path, k_shot, q_query, task_num=10), [5, 5]\n",
        "    )\n",
        "    (train_loader, val_loader), (train_iter, val_iter) = dataloader_init((train_set, val_set), shuffle=False)\n",
        "\n",
        "elif solver == 'meta':\n",
        "    Solver = MetaSolver\n",
        "    dataset = Omniglot(train_data_path, k_shot, q_query)\n",
        "    train_split = int(0.8 * len(dataset))\n",
        "    val_split = len(dataset) - train_split\n",
        "    train_set, val_set = torch.utils.data.random_split(\n",
        "        dataset, [train_split, val_split]\n",
        "    )\n",
        "    (train_loader, val_loader), (train_iter, val_iter) = dataloader_init((train_set, val_set))\n",
        "else:\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "# main training loop\n",
        "for epoch in range(max_epoch):\n",
        "    print(\"Epoch %d\" % (epoch + 1))\n",
        "    train_meta_loss = []\n",
        "    train_acc = []\n",
        "    # The \"step\" here is a meta-gradinet update step\n",
        "    for step in tqdm(range(max(1, len(train_loader) // meta_batch_size))):\n",
        "        x, train_iter = get_meta_batch(\n",
        "            meta_batch_size, k_shot, q_query, train_loader, train_iter\n",
        "        )\n",
        "        meta_loss, acc = Solver(\n",
        "            meta_model,\n",
        "            optimizer,\n",
        "            x,\n",
        "            n_way,\n",
        "            k_shot,\n",
        "            q_query,\n",
        "            loss_fn,\n",
        "            inner_train_step=train_inner_train_step\n",
        "        )\n",
        "        train_meta_loss.append(meta_loss.item())\n",
        "        train_acc.append(acc)\n",
        "    print(\"  Loss    : \", \"%.3f\" % (np.mean(train_meta_loss)), end=\"\\t\")\n",
        "    print(\"  Accuracy: \", \"%.3f %%\" % (np.mean(train_acc) * 100))\n",
        "\n",
        "    # See the validation accuracy after each epoch.\n",
        "    # Early stopping is welcomed to implement.\n",
        "    val_acc = []\n",
        "    for eval_step in tqdm(range(max(1, len(val_loader) // (eval_batches)))):\n",
        "        x, val_iter = get_meta_batch(\n",
        "            eval_batches, k_shot, q_query, val_loader, val_iter\n",
        "        )\n",
        "        # We update three inner steps when testing.\n",
        "        _, acc = Solver(\n",
        "            meta_model,\n",
        "            optimizer,\n",
        "            x,\n",
        "            n_way,\n",
        "            k_shot,\n",
        "            q_query,\n",
        "            loss_fn,\n",
        "            inner_train_step=val_inner_train_step,\n",
        "            train=False,\n",
        "        )\n",
        "        val_acc.append(acc)\n",
        "    print(\"  Validation accuracy: \", \"%.3f %%\" % (np.mean(val_acc) * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5Ew8-POf9sw"
      },
      "source": [
        "### Testing the result\n",
        "\n",
        "Since the testing data is sampled in advance, you should not change the code in `OmnigloTest` dataset, otherwise your score may not be correct.\n",
        "\n",
        "However, fell free to chagne the variable `inner_train_step` to set the training steps on the query set images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "OKtTzxZeln5Z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "# test dataset\n",
        "class OmniglotTest(Dataset):\n",
        "    def __init__(self, test_dir):\n",
        "        self.test_dir = test_dir\n",
        "        self.n = 5\n",
        "\n",
        "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        support_files = [\n",
        "            os.path.join(self.test_dir, \"support\", f\"{idx:>04}\", f\"image_{i}.png\")\n",
        "            for i in range(self.n)\n",
        "        ]\n",
        "        query_files = [\n",
        "            os.path.join(self.test_dir, \"query\", f\"{idx:>04}\", f\"image_{i}.png\")\n",
        "            for i in range(self.n)\n",
        "        ]\n",
        "\n",
        "        support_imgs = torch.stack(\n",
        "            [self.transform(Image.open(e)) for e in support_files]\n",
        "        )\n",
        "        query_imgs = torch.stack([self.transform(Image.open(e)) for e in query_files])\n",
        "\n",
        "        return support_imgs, query_imgs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(os.listdir(os.path.join(self.test_dir, \"support\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "kTWHs1RThgGc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:24<00:00,  1.30it/s]\n"
          ]
        }
      ],
      "source": [
        "test_inner_train_step = 30 # you can change this\n",
        "\n",
        "test_batches = 20\n",
        "test_dataset = OmniglotTest(\"Omniglot-test\")\n",
        "test_loader = DataLoader(test_dataset, batch_size=test_batches, shuffle=False)\n",
        "\n",
        "output = []\n",
        "for _, batch in enumerate(tqdm(test_loader)):\n",
        "    support_set, query_set = batch\n",
        "    x = torch.cat([support_set, query_set], dim=1)\n",
        "    x = x.to(device)\n",
        "\n",
        "    labels = Solver(\n",
        "        meta_model,\n",
        "        optimizer,\n",
        "        x,\n",
        "        n_way,\n",
        "        k_shot,\n",
        "        q_query,\n",
        "        loss_fn,\n",
        "        inner_train_step=test_inner_train_step,\n",
        "        train=False,\n",
        "        return_labels=True,\n",
        "    )\n",
        "\n",
        "    output.extend(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "kYOd98juJL6q"
      },
      "outputs": [],
      "source": [
        "# write to csv\n",
        "with open(\"meta_output.csv\", \"w\") as f:\n",
        "    f.write(f\"id,class\\n\")\n",
        "    for i, label in enumerate(output):\n",
        "        f.write(f\"{i},{label}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIfamxgMIaXw"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Meta Test Accuracy: 76.69%\n",
            "\n",
            "Base Test Accuracy: 60.84%\n"
          ]
        }
      ],
      "source": [
        "meta_output_path = \"meta_output.csv\"\n",
        "base_output_path = \"base_output.csv\"\n",
        "\n",
        "true_labels_path = \"true_labels.csv\"\n",
        "\n",
        "true_labels = np.array(pd.read_csv(true_labels_path)['class'])\n",
        "\n",
        "meta_output = np.array(pd.read_csv(meta_output_path)['class'])\n",
        "base_output = np.array(pd.read_csv(base_output_path)['class'])\n",
        "\n",
        "meta_accuracy = np.mean(np.array(meta_output) == np.array(true_labels))\n",
        "base_accuracy = np.mean(np.array(base_output) == np.array(true_labels))\n",
        "\n",
        "print(f\"\\nMeta Test Accuracy: {meta_accuracy * 100:.2f}%\")\n",
        "print(f\"\\nBase Test Accuracy: {base_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtD8X3RLf-6w"
      },
      "source": [
        "## **Reference**\n",
        "1. Chelsea Finn, Pieter Abbeel, & Sergey Levine. (2017). [Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.](https://arxiv.org/abs/1909.09157)\n",
        "1. Aniruddh Raghu, Maithra Raghu, Samy Bengio, & Oriol Vinyals. (2020). [Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML.](https://arxiv.org/abs/1909.09157)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
